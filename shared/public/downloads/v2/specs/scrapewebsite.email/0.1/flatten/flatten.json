{
	"basePath": "/",
	"host": "scrapewebsite.email",
	"info.description": "ScrapeWebsiteEmail is a service that exposes an api to fetch e-mails from a website.",
	"info.title": "Scrape Website Email API",
	"info.version": "0.1",
	"info.x-apisguru-categories.length": 2,
	"info.x-apisguru-categories[0]": "email",
	"info.x-apisguru-categories[1]": "tools",
	"info.x-origin.length": 1,
	"info.x-origin[0].converter.url": "https://github.com/lucybot/api-spec-converter",
	"info.x-origin[0].converter.version": "2.5.0",
	"info.x-origin[0].format": "swagger",
	"info.x-origin[0].url": "http://scrapewebsite.email/v1/swagger_doc.json",
	"info.x-origin[0].version": "1.2",
	"info.x-preferred": true,
	"info.x-providerName": "scrapewebsite.email",
	"paths./v1/ping.json.get.description": "\u003cp\u003eReturns ‘pong’ if the site is up\u003c/p\u003e\n",
	"paths./v1/ping.json.get.operationId": "GET-v1-ping---format-",
	"paths./v1/ping.json.get.responses.200.description": "No response was specified",
	"paths./v1/ping.json.get.summary": "Returns whether the system is up.",
	"paths./v1/ping.json.get.tags.length": 1,
	"paths./v1/ping.json.get.tags[0]": "ping",
	"paths./v1/scrape_emails.json.get.operationId": "GET-v1-scrape_emails---format-",
	"paths./v1/scrape_emails.json.get.parameters.length": 2,
	"paths./v1/scrape_emails.json.get.parameters[0].description": "\u003cp\u003eThe website (ie. www.soundflair.com)\u003c/p\u003e\n",
	"paths./v1/scrape_emails.json.get.parameters[0].in": "query",
	"paths./v1/scrape_emails.json.get.parameters[0].name": "website",
	"paths./v1/scrape_emails.json.get.parameters[0].required": true,
	"paths./v1/scrape_emails.json.get.parameters[0].type": "string",
	"paths./v1/scrape_emails.json.get.parameters[1].description": "\u003ctable\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003ctd\u003eOptional. The word(s) that the webpage must include (otherwise it will skip scraping that page). Good if you want to scrape only contact pages. Takes regex (ie. about\u003c/td\u003e\n      \u003ctd\u003econtact).\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n",
	"paths./v1/scrape_emails.json.get.parameters[1].in": "query",
	"paths./v1/scrape_emails.json.get.parameters[1].name": "must_include",
	"paths./v1/scrape_emails.json.get.parameters[1].required": false,
	"paths./v1/scrape_emails.json.get.parameters[1].type": "string",
	"paths./v1/scrape_emails.json.get.responses.200.description": "No response was specified",
	"paths./v1/scrape_emails.json.get.summary": "Returns a list of emails scraped by priority (ie. e-mails appear on top level pages are first). Please note that subsequent calls to the same url will be fetched from the \u003cb\u003ecache\u003c/b\u003e (14 day flush). \u003cbr/\u003e\u003cbr/\u003eWill also parse patterns such as hello[at]site.com, hello[at]site[dot]com, hello(at)site.com, hello(at)site(dot)com, hello @ site.com, hello @ site . com. \u003cbr/\u003e\u003cbr/\u003ePlease do note we cannot parse sites that require a login (for now), so for some Facebook pages it is not possible at the moment to fetch the e-mail.\u003cbr/\u003e\u003cbr/\u003eFinally, please note that the api will fetch links for up to 2 minutes. After that time it will start analysing the pages which have been scraped. \u003cb\u003eTherefore\u003c/b\u003e please ensure that your client has a timeout of at least \u003cb\u003e150 seconds\u003c/b\u003e (2 mins to fetch and the rest to parse). \u003cbr/\u003e\u003cbr/\u003e\u003cb\u003ePlease note\u003c/b\u003e that due to the fact that the api goes out to fetch the pages, the server allows only 1 concurrent request/ip. Requests which are made while the 1 request is still processing will result in a 429 code.\u003cbr/\u003e\u003cbr/\u003e\u003cb\u003ePlease note\u003c/b\u003e that as of May 25, 2014, the main mechanism of tracking usage will be done via Mashape. You can get the free calls by signing up with the FREE plan.\u003cbr/\u003e\u003cbr/\u003ePlease visit \u003ca href='https://www.mashape.com/tommytcchan/scrape-website-email'\u003ehttps://www.mashape.com/tommytcchan/scrape-website-email\u003c/a\u003e.\u003cbr/\u003e\u003cbr/\u003e\u003cb\u003eThere is now a limit of 5 requests per day using this sample interface.\u003c/b\u003e\u003cbr/\u003e\u003cbr/\u003e",
	"paths./v1/scrape_emails.json.get.tags.length": 1,
	"paths./v1/scrape_emails.json.get.tags[0]": "scrape_emails",
	"paths./v1/scrape_store_links.json.get.operationId": "GET-v1-scrape_store_links---format-",
	"paths./v1/scrape_store_links.json.get.parameters.length": 1,
	"paths./v1/scrape_store_links.json.get.parameters[0].description": "\u003cp\u003eThe website (ie. www.soundflair.com)\u003c/p\u003e\n",
	"paths./v1/scrape_store_links.json.get.parameters[0].in": "query",
	"paths./v1/scrape_store_links.json.get.parameters[0].name": "website",
	"paths./v1/scrape_store_links.json.get.parameters[0].required": true,
	"paths./v1/scrape_store_links.json.get.parameters[0].type": "string",
	"paths./v1/scrape_store_links.json.get.responses.200.description": "No response was specified",
	"paths./v1/scrape_store_links.json.get.summary": "Attempts to grab the google store url or the ios store url for a site, after searching through the site.",
	"paths./v1/scrape_store_links.json.get.tags.length": 1,
	"paths./v1/scrape_store_links.json.get.tags[0]": "scrape_store_links",
	"produces.length": 1,
	"produces[0]": "application/json",
	"schemes.length": 1,
	"schemes[0]": "http",
	"swagger": "2.0",
	"tags.length": 3,
	"tags[0].name": "ping",
	"tags[1].name": "scrape_emails",
	"tags[2].name": "scrape_store_links"
}