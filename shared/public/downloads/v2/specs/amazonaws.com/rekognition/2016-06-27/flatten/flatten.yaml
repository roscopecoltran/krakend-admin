basePath: /
consumes.length: 1
consumes[0]: application/json
definitions.AccessDeniedException.description: You are not authorized to perform the
  action.
definitions.AccessDeniedException.type: object
definitions.AgeRange.description: <p>Structure containing the estimated age range,
  in years, for a face.</p> <p>Rekognition estimates an age-range for faces detected
  in the input image. Estimated age ranges can overlap; a face of a 5 year old may
  have an estimated range of 4-6 whilst the face of a 6 year old may have an estimated
  range of 4-8.</p>
definitions.AgeRange.properties.High.$ref: '#/definitions/UInteger'
definitions.AgeRange.properties.High.description: The highest estimated age.
definitions.AgeRange.properties.Low.$ref: '#/definitions/UInteger'
definitions.AgeRange.properties.Low.description: The lowest estimated age.
definitions.AgeRange.type: object
definitions.Attribute.enum.length: 2
definitions.Attribute.enum[0]: DEFAULT
definitions.Attribute.enum[1]: ALL
definitions.Attribute.type: string
definitions.Attributes.items.$ref: '#/definitions/Attribute'
definitions.Attributes.type: array
definitions.Beard.description: Indicates whether or not the face has a beard, and
  the confidence level in the determination.
definitions.Beard.properties.Confidence.$ref: '#/definitions/Percent'
definitions.Beard.properties.Confidence.description: Level of confidence in the determination.
definitions.Beard.properties.Value.$ref: '#/definitions/Boolean'
definitions.Beard.properties.Value.description: Boolean value that indicates whether
  the face has beard or not.
definitions.Beard.type: object
definitions.Boolean.type: boolean
definitions.BoundingBox.description: <p>Identifies the bounding box around the object
  or face. The <code>left</code> (x-coordinate) and <code>top</code> (y-coordinate)
  are coordinates representing the top and left sides of the bounding box. Note that
  the upper-left corner of the image is the origin (0,0). </p> <p>The <code>top</code>
  and <code>left</code> values returned are ratios of the overall image size. For
  example, if the input image is 700x200 pixels, and the top-left coordinate of the
  bounding box is 350x50 pixels, the API returns a <code>left</code> value of 0.5
  (350/700) and a <code>top</code> value of 0.25 (50/200).</p> <p> The <code>width</code>
  and <code>height</code> values represent the dimensions of the bounding box as a
  ratio of the overall image dimension. For example, if the input image is 700x200
  pixels, and the bounding box width is 70 pixels, the width returned is 0.1. </p>
  <note> <p> The bounding box coordinates can have negative values. For example, if
  Amazon Rekognition is able to detect a face that is at the image edge and is only
  partially visible, the service can return coordinates that are outside the image
  bounds and, depending on the image edge, you might get negative values or values
  greater than 1 for the <code>left</code> or <code>top</code> values. </p> </note>
definitions.BoundingBox.properties.Height.$ref: '#/definitions/Float'
definitions.BoundingBox.properties.Height.description: Height of the bounding box
  as a ratio of the overall image height.
definitions.BoundingBox.properties.Left.$ref: '#/definitions/Float'
definitions.BoundingBox.properties.Left.description: Left coordinate of the bounding
  box as a ratio of overall image width.
definitions.BoundingBox.properties.Top.$ref: '#/definitions/Float'
definitions.BoundingBox.properties.Top.description: Top coordinate of the bounding
  box as a ratio of overall image height.
definitions.BoundingBox.properties.Width.$ref: '#/definitions/Float'
definitions.BoundingBox.properties.Width.description: Width of the bounding box as
  a ratio of the overall image width.
definitions.BoundingBox.type: object
definitions.Celebrity.description: Provides information about a celebrity recognized
  by the operation.
definitions.Celebrity.properties.Face.$ref: '#/definitions/ComparedFace'
definitions.Celebrity.properties.Face.description: Provides information about the
  celebrity's face, such as its location on the image.
definitions.Celebrity.properties.Id.$ref: '#/definitions/RekognitionUniqueId'
definitions.Celebrity.properties.Id.description: 'A unique identifier for the celebrity. '
definitions.Celebrity.properties.MatchConfidence.$ref: '#/definitions/Percent'
definitions.Celebrity.properties.MatchConfidence.description: The confidence, in percentage,
  that Rekognition has that the recognized face is the celebrity.
definitions.Celebrity.properties.Name.$ref: '#/definitions/String'
definitions.Celebrity.properties.Name.description: The name of the celebrity.
definitions.Celebrity.properties.Urls.$ref: '#/definitions/Urls'
definitions.Celebrity.properties.Urls.description: An array of URLs pointing to additional
  information about the celebrity. If there is no additional information about the
  celebrity, this list is empty.
definitions.Celebrity.type: object
definitions.CelebrityList.items.$ref: '#/definitions/Celebrity'
definitions.CelebrityList.type: array
definitions.CollectionId.maxLength: 255
definitions.CollectionId.minLength: 1
definitions.CollectionId.pattern: '[a-zA-Z0-9_.\-]+'
definitions.CollectionId.type: string
definitions.CollectionIdList.items.$ref: '#/definitions/CollectionId'
definitions.CollectionIdList.type: array
definitions.CompareFacesMatch.description: Provides information about a face in a
  target image that matches the source image face analysed by <code>CompareFaces</code>.
  The <code>Face</code> property contains the bounding box of the face in the target
  image. The <code>Similarity</code> property is the confidence that the source image
  face matches the face in the bounding box.
definitions.CompareFacesMatch.properties.Face.$ref: '#/definitions/ComparedFace'
definitions.CompareFacesMatch.properties.Face.description: Provides face metadata
  (bounding box and confidence that the bounding box actually contains a face).
definitions.CompareFacesMatch.properties.Similarity.$ref: '#/definitions/Percent'
definitions.CompareFacesMatch.properties.Similarity.description: Level of confidence
  that the faces match.
definitions.CompareFacesMatch.type: object
definitions.CompareFacesMatchList.items.$ref: '#/definitions/CompareFacesMatch'
definitions.CompareFacesMatchList.type: array
definitions.CompareFacesRequest.example.SimilarityThreshold: 90
definitions.CompareFacesRequest.example.SourceImage.S3Object.Bucket: mybucket
definitions.CompareFacesRequest.example.SourceImage.S3Object.Name: mysourceimage
definitions.CompareFacesRequest.example.TargetImage.S3Object.Bucket: mybucket
definitions.CompareFacesRequest.example.TargetImage.S3Object.Name: mytargetimage
definitions.CompareFacesRequest.properties.SimilarityThreshold.$ref: '#/definitions/Percent'
definitions.CompareFacesRequest.properties.SimilarityThreshold.description: The minimum
  level of confidence in the face matches that a match must meet to be included in
  the <code>FaceMatches</code> array.
definitions.CompareFacesRequest.properties.SourceImage.$ref: '#/definitions/Image'
definitions.CompareFacesRequest.properties.SourceImage.description: The source image,
  either as bytes or as an S3 object.
definitions.CompareFacesRequest.properties.TargetImage.$ref: '#/definitions/Image'
definitions.CompareFacesRequest.properties.TargetImage.description: The target image,
  either as bytes or as an S3 object.
definitions.CompareFacesRequest.required.length: 2
definitions.CompareFacesRequest.required[0]: SourceImage
definitions.CompareFacesRequest.required[1]: TargetImage
definitions.CompareFacesRequest.type: object
definitions.CompareFacesResponse.example.FaceMatches.length: 1
definitions.CompareFacesResponse.example.FaceMatches[0].Face.BoundingBox.Height: 0.33481482
definitions.CompareFacesResponse.example.FaceMatches[0].Face.BoundingBox.Left: 0.3188889
definitions.CompareFacesResponse.example.FaceMatches[0].Face.BoundingBox.Top: 0.49333334
definitions.CompareFacesResponse.example.FaceMatches[0].Face.BoundingBox.Width: 0.25
definitions.CompareFacesResponse.example.FaceMatches[0].Face.Confidence: 99.99912
definitions.CompareFacesResponse.example.FaceMatches[0].Similarity: 100
definitions.CompareFacesResponse.example.SourceImageFace.BoundingBox.Height: 0.33481482
definitions.CompareFacesResponse.example.SourceImageFace.BoundingBox.Left: 0.3188889
definitions.CompareFacesResponse.example.SourceImageFace.BoundingBox.Top: 0.49333334
definitions.CompareFacesResponse.example.SourceImageFace.BoundingBox.Width: 0.25
definitions.CompareFacesResponse.example.SourceImageFace.Confidence: 99.99912
definitions.CompareFacesResponse.properties.FaceMatches.$ref: '#/definitions/CompareFacesMatchList'
definitions.CompareFacesResponse.properties.FaceMatches.description: An array of faces
  in the target image that match the source image face. Each <code>CompareFacesMatch</code>
  object provides the bounding box, the confidence level that the bounding box contains
  a face, and the similarity score for the face in the bounding box and the face in
  the source image.
definitions.CompareFacesResponse.properties.SourceImageFace.$ref: '#/definitions/ComparedSourceImageFace'
definitions.CompareFacesResponse.properties.SourceImageFace.description: The face
  in the source image that was used for comparison.
definitions.CompareFacesResponse.properties.SourceImageOrientationCorrection.$ref: '#/definitions/OrientationCorrection'
definitions.CompareFacesResponse.properties.SourceImageOrientationCorrection.description: <p>
  The orientation of the source image (counterclockwise direction). If your application
  displays the source image, you can use this value to correct image orientation.
  The bounding box coordinates returned in <code>SourceImageFace</code> represent
  the location of the face before the image orientation is corrected. </p> <note>
  <p>If the source image is in .jpeg format, it might contain exchangeable image (Exif)
  metadata that includes the image's orientation. If the Exif metadata for the source
  image populates the orientation field, the value of <code>OrientationCorrection</code>
  is null and the <code>SourceImageFace</code> bounding box coordinates represent
  the location of the face after Exif metadata is used to correct the orientation.
  Images in .png format don't contain Exif metadata.</p> </note>
definitions.CompareFacesResponse.properties.TargetImageOrientationCorrection.$ref: '#/definitions/OrientationCorrection'
definitions.CompareFacesResponse.properties.TargetImageOrientationCorrection.description: <p>
  The orientation of the target image (in counterclockwise direction). If your application
  displays the target image, you can use this value to correct the orientation of
  the image. The bounding box coordinates returned in <code>FaceMatches</code> and
  <code>UnmatchedFaces</code> represent face locations before the image orientation
  is corrected. </p> <note> <p>If the target image is in .jpg format, it might contain
  Exif metadata that includes the orientation of the image. If the Exif metadata for
  the target image populates the orientation field, the value of <code>OrientationCorrection</code>
  is null and the bounding box coordinates in <code>FaceMatches</code> and <code>UnmatchedFaces</code>
  represent the location of the face after Exif metadata is used to correct the orientation.
  Images in .png format don't contain Exif metadata.</p> </note>
definitions.CompareFacesResponse.properties.UnmatchedFaces.$ref: '#/definitions/CompareFacesUnmatchList'
definitions.CompareFacesResponse.properties.UnmatchedFaces.description: An array of
  faces in the target image that did not match the source image face.
definitions.CompareFacesResponse.type: object
definitions.CompareFacesUnmatchList.items.$ref: '#/definitions/ComparedFace'
definitions.CompareFacesUnmatchList.type: array
definitions.ComparedFace.description: Provides face metadata for target image faces
  that are analysed by <code>CompareFaces</code> and <code>RecognizeCelebrities</code>.
definitions.ComparedFace.properties.BoundingBox.$ref: '#/definitions/BoundingBox'
definitions.ComparedFace.properties.BoundingBox.description: Bounding box of the face.
definitions.ComparedFace.properties.Confidence.$ref: '#/definitions/Percent'
definitions.ComparedFace.properties.Confidence.description: Level of confidence that
  what the bounding box contains is a face.
definitions.ComparedFace.properties.Landmarks.$ref: '#/definitions/Landmarks'
definitions.ComparedFace.properties.Landmarks.description: An array of facial landmarks.
definitions.ComparedFace.properties.Pose.$ref: '#/definitions/Pose'
definitions.ComparedFace.properties.Pose.description: Indicates the pose of the face
  as determined by its pitch, roll, and yaw.
definitions.ComparedFace.properties.Quality.$ref: '#/definitions/ImageQuality'
definitions.ComparedFace.properties.Quality.description: 'Identifies face image brightness
  and sharpness. '
definitions.ComparedFace.type: object
definitions.ComparedFaceList.items.$ref: '#/definitions/ComparedFace'
definitions.ComparedFaceList.type: array
definitions.ComparedSourceImageFace.description: 'Type that describes the face Amazon
  Rekognition chose to compare with the faces in the target. This contains a bounding
  box for the selected face and confidence level that the bounding box contains a
  face. Note that Amazon Rekognition selects the largest face in the source image
  for this comparison. '
definitions.ComparedSourceImageFace.properties.BoundingBox.$ref: '#/definitions/BoundingBox'
definitions.ComparedSourceImageFace.properties.BoundingBox.description: Bounding box
  of the face.
definitions.ComparedSourceImageFace.properties.Confidence.$ref: '#/definitions/Percent'
definitions.ComparedSourceImageFace.properties.Confidence.description: Confidence
  level that the selected bounding box contains a face.
definitions.ComparedSourceImageFace.type: object
definitions.CreateCollectionRequest.example.CollectionId: myphotos
definitions.CreateCollectionRequest.properties.CollectionId.$ref: '#/definitions/CollectionId'
definitions.CreateCollectionRequest.properties.CollectionId.description: ID for the
  collection that you are creating.
definitions.CreateCollectionRequest.required.length: 1
definitions.CreateCollectionRequest.required[0]: CollectionId
definitions.CreateCollectionRequest.type: object
definitions.CreateCollectionResponse.example.CollectionArn: aws:rekognition:us-west-2:123456789012:collection/myphotos
definitions.CreateCollectionResponse.example.StatusCode: 200
definitions.CreateCollectionResponse.properties.CollectionArn.$ref: '#/definitions/String'
definitions.CreateCollectionResponse.properties.CollectionArn.description: 'Amazon
  Resource Name (ARN) of the collection. You can use this to manage permissions on
  your resources. '
definitions.CreateCollectionResponse.properties.StatusCode.$ref: '#/definitions/UInteger'
definitions.CreateCollectionResponse.properties.StatusCode.description: HTTP status
  code indicating the result of the operation.
definitions.CreateCollectionResponse.type: object
definitions.Degree.format: float
definitions.Degree.maximum: 180
definitions.Degree.minimum: -180
definitions.Degree.type: number
definitions.DeleteCollectionRequest.example.CollectionId: myphotos
definitions.DeleteCollectionRequest.properties.CollectionId.$ref: '#/definitions/CollectionId'
definitions.DeleteCollectionRequest.properties.CollectionId.description: ID of the
  collection to delete.
definitions.DeleteCollectionRequest.required.length: 1
definitions.DeleteCollectionRequest.required[0]: CollectionId
definitions.DeleteCollectionRequest.type: object
definitions.DeleteCollectionResponse.example.StatusCode: 200
definitions.DeleteCollectionResponse.properties.StatusCode.$ref: '#/definitions/UInteger'
definitions.DeleteCollectionResponse.properties.StatusCode.description: HTTP status
  code that indicates the result of the operation.
definitions.DeleteCollectionResponse.type: object
definitions.DeleteFacesRequest.example.CollectionId: myphotos
definitions.DeleteFacesRequest.example.FaceIds.length: 1
definitions.DeleteFacesRequest.example.FaceIds[0]: ff43d742-0c13-5d16-a3e8-03d3f58e980b
definitions.DeleteFacesRequest.properties.CollectionId.$ref: '#/definitions/CollectionId'
definitions.DeleteFacesRequest.properties.CollectionId.description: Collection from
  which to remove the specific faces.
definitions.DeleteFacesRequest.properties.FaceIds.$ref: '#/definitions/FaceIdList'
definitions.DeleteFacesRequest.properties.FaceIds.description: An array of face IDs
  to delete.
definitions.DeleteFacesRequest.required.length: 2
definitions.DeleteFacesRequest.required[0]: CollectionId
definitions.DeleteFacesRequest.required[1]: FaceIds
definitions.DeleteFacesRequest.type: object
definitions.DeleteFacesResponse.example.DeletedFaces.length: 1
definitions.DeleteFacesResponse.example.DeletedFaces[0]: ff43d742-0c13-5d16-a3e8-03d3f58e980b
definitions.DeleteFacesResponse.properties.DeletedFaces.$ref: '#/definitions/FaceIdList'
definitions.DeleteFacesResponse.properties.DeletedFaces.description: An array of strings
  (face IDs) of the faces that were deleted.
definitions.DeleteFacesResponse.type: object
definitions.DetectFacesRequest.example.Image.S3Object.Bucket: mybucket
definitions.DetectFacesRequest.example.Image.S3Object.Name: myphoto
definitions.DetectFacesRequest.properties.Attributes.$ref: '#/definitions/Attributes'
definitions.DetectFacesRequest.properties.Attributes.description: '<p>An array of
  facial attributes you want to be returned. This can be the default list of attributes
  or all attributes. If you don''t specify a value for <code>Attributes</code> or
  if you specify <code>["DEFAULT"]</code>, the API returns the following subset of
  facial attributes: <code>BoundingBox</code>, <code>Confidence</code>, <code>Pose</code>,
  <code>Quality</code> and <code>Landmarks</code>. If you provide <code>["ALL"]</code>,
  all facial attributes are returned but the operation will take longer to complete.</p>
  <p>If you provide both, <code>["ALL", "DEFAULT"]</code>, the service uses a logical
  AND operator to determine which attributes to return (in this case, all attributes).
  </p>'
definitions.DetectFacesRequest.properties.Image.$ref: '#/definitions/Image'
definitions.DetectFacesRequest.properties.Image.description: 'The image in which you
  want to detect faces. You can specify a blob or an S3 object. '
definitions.DetectFacesRequest.required.length: 1
definitions.DetectFacesRequest.required[0]: Image
definitions.DetectFacesRequest.type: object
definitions.DetectFacesResponse.example.FaceDetails.length: 1
definitions.DetectFacesResponse.example.FaceDetails[0].BoundingBox.Height: 0.18
definitions.DetectFacesResponse.example.FaceDetails[0].BoundingBox.Left: 0.5555556
definitions.DetectFacesResponse.example.FaceDetails[0].BoundingBox.Top: 0.33666667
definitions.DetectFacesResponse.example.FaceDetails[0].BoundingBox.Width: 0.24
definitions.DetectFacesResponse.example.FaceDetails[0].Confidence: 100
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks.length: 5
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[0].Type: eyeLeft
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[0].X: 0.63947374
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[0].Y: 0.40819624
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[1].Type: eyeRight
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[1].X: 0.7266661
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[1].Y: 0.41039225
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[2].Type: eyeRight
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[2].X: 0.6912462
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[2].Y: 0.4424096
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[3].Type: mouthDown
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[3].X: 0.6306198
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[3].Y: 0.4670004
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[4].Type: mouthUp
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[4].X: 0.7215609
definitions.DetectFacesResponse.example.FaceDetails[0].Landmarks[4].Y: 0.47114262
definitions.DetectFacesResponse.example.FaceDetails[0].Pose.Pitch: 4.0508065
definitions.DetectFacesResponse.example.FaceDetails[0].Pose.Roll: 0.99507475
definitions.DetectFacesResponse.example.FaceDetails[0].Pose.Yaw: 13.69379
definitions.DetectFacesResponse.example.FaceDetails[0].Quality.Brightness: 37.6017
definitions.DetectFacesResponse.example.FaceDetails[0].Quality.Sharpness: 80
definitions.DetectFacesResponse.example.OrientationCorrection: ROTATE_0
definitions.DetectFacesResponse.properties.FaceDetails.$ref: '#/definitions/FaceDetailList'
definitions.DetectFacesResponse.properties.FaceDetails.description: 'Details of each
  face found in the image. '
definitions.DetectFacesResponse.properties.OrientationCorrection.$ref: '#/definitions/OrientationCorrection'
definitions.DetectFacesResponse.properties.OrientationCorrection.description: <p>
  The orientation of the input image (counter-clockwise direction). If your application
  displays the image, you can use this value to correct image orientation. The bounding
  box coordinates returned in <code>FaceDetails</code> represent face locations before
  the image orientation is corrected. </p> <note> <p>If the input image is in .jpeg
  format, it might contain exchangeable image (Exif) metadata that includes the image's
  orientation. If so, and the Exif metadata for the input image populates the orientation
  field, the value of <code>OrientationCorrection</code> is null and the <code>FaceDetails</code>
  bounding box coordinates represent face locations after Exif metadata is used to
  correct the image orientation. Images in .png format don't contain Exif metadata.</p>
  </note>
definitions.DetectFacesResponse.type: object
definitions.DetectLabelsRequest.example.Image.S3Object.Bucket: mybucket
definitions.DetectLabelsRequest.example.Image.S3Object.Name: myphoto
definitions.DetectLabelsRequest.example.MaxLabels: 123
definitions.DetectLabelsRequest.example.MinConfidence: 70
definitions.DetectLabelsRequest.properties.Image.$ref: '#/definitions/Image'
definitions.DetectLabelsRequest.properties.Image.description: The input image. You
  can provide a blob of image bytes or an S3 object.
definitions.DetectLabelsRequest.properties.MaxLabels.$ref: '#/definitions/UInteger'
definitions.DetectLabelsRequest.properties.MaxLabels.description: 'Maximum number
  of labels you want the service to return in the response. The service returns the
  specified number of highest confidence labels. '
definitions.DetectLabelsRequest.properties.MinConfidence.$ref: '#/definitions/Percent'
definitions.DetectLabelsRequest.properties.MinConfidence.description: <p>Specifies
  the minimum confidence level for the labels to return. Amazon Rekognition doesn't
  return any labels with confidence lower than this specified value.</p> <p>If <code>MinConfidence</code>
  is not specified, the operation returns labels with a confidence values greater
  than or equal to 50 percent.</p>
definitions.DetectLabelsRequest.required.length: 1
definitions.DetectLabelsRequest.required[0]: Image
definitions.DetectLabelsRequest.type: object
definitions.DetectLabelsResponse.example.Labels.length: 2
definitions.DetectLabelsResponse.example.Labels[0].Confidence: 99.250725
definitions.DetectLabelsResponse.example.Labels[0].Name: People
definitions.DetectLabelsResponse.example.Labels[1].Confidence: 99.25074
definitions.DetectLabelsResponse.example.Labels[1].Name: Person
definitions.DetectLabelsResponse.properties.Labels.$ref: '#/definitions/Labels'
definitions.DetectLabelsResponse.properties.Labels.description: 'An array of labels
  for the real-world objects detected. '
definitions.DetectLabelsResponse.properties.OrientationCorrection.$ref: '#/definitions/OrientationCorrection'
definitions.DetectLabelsResponse.properties.OrientationCorrection.description: <p>
  The orientation of the input image (counter-clockwise direction). If your application
  displays the image, you can use this value to correct the orientation. If Amazon
  Rekognition detects that the input image was rotated (for example, by 90 degrees),
  it first corrects the orientation before detecting the labels. </p> <note> <p>If
  the input image Exif metadata populates the orientation field, Amazon Rekognition
  does not perform orientation correction and the value of OrientationCorrection will
  be null.</p> </note>
definitions.DetectLabelsResponse.type: object
definitions.DetectModerationLabelsRequest.properties.Image.$ref: '#/definitions/Image'
definitions.DetectModerationLabelsRequest.properties.Image.description: The input
  image as bytes or an S3 object.
definitions.DetectModerationLabelsRequest.properties.MinConfidence.$ref: '#/definitions/Percent'
definitions.DetectModerationLabelsRequest.properties.MinConfidence.description: <p>Specifies
  the minimum confidence level for the labels to return. Amazon Rekognition doesn't
  return any labels with a confidence level lower than this specified value.</p> <p>If
  you don't specify <code>MinConfidence</code>, the operation returns labels with
  confidence values greater than or equal to 50 percent.</p>
definitions.DetectModerationLabelsRequest.required.length: 1
definitions.DetectModerationLabelsRequest.required[0]: Image
definitions.DetectModerationLabelsRequest.type: object
definitions.DetectModerationLabelsResponse.properties.ModerationLabels.$ref: '#/definitions/ModerationLabels'
definitions.DetectModerationLabelsResponse.properties.ModerationLabels.description: 'An
  array of labels for explicit or suggestive adult content found in the image. The
  list includes the top-level label and each child label detected in the image. This
  is useful for filtering specific categories of content. '
definitions.DetectModerationLabelsResponse.type: object
definitions.Emotion.description: The emotions detected on the face, and the confidence
  level in the determination. For example, HAPPY, SAD, and ANGRY.
definitions.Emotion.properties.Confidence.$ref: '#/definitions/Percent'
definitions.Emotion.properties.Confidence.description: Level of confidence in the
  determination.
definitions.Emotion.properties.Type.$ref: '#/definitions/EmotionName'
definitions.Emotion.properties.Type.description: Type of emotion detected.
definitions.Emotion.type: object
definitions.EmotionName.enum.length: 8
definitions.EmotionName.enum[0]: HAPPY
definitions.EmotionName.enum[1]: SAD
definitions.EmotionName.enum[2]: ANGRY
definitions.EmotionName.enum[3]: CONFUSED
definitions.EmotionName.enum[4]: DISGUSTED
definitions.EmotionName.enum[5]: SURPRISED
definitions.EmotionName.enum[6]: CALM
definitions.EmotionName.enum[7]: UNKNOWN
definitions.EmotionName.type: string
definitions.Emotions.items.$ref: '#/definitions/Emotion'
definitions.Emotions.type: array
definitions.ExternalImageId.maxLength: 255
definitions.ExternalImageId.minLength: 1
definitions.ExternalImageId.pattern: '[a-zA-Z0-9_.\-:]+'
definitions.ExternalImageId.type: string
definitions.EyeOpen.description: Indicates whether or not the eyes on the face are
  open, and the confidence level in the determination.
definitions.EyeOpen.properties.Confidence.$ref: '#/definitions/Percent'
definitions.EyeOpen.properties.Confidence.description: Level of confidence in the
  determination.
definitions.EyeOpen.properties.Value.$ref: '#/definitions/Boolean'
definitions.EyeOpen.properties.Value.description: Boolean value that indicates whether
  the eyes on the face are open.
definitions.EyeOpen.type: object
definitions.Eyeglasses.description: Indicates whether or not the face is wearing eye
  glasses, and the confidence level in the determination.
definitions.Eyeglasses.properties.Confidence.$ref: '#/definitions/Percent'
definitions.Eyeglasses.properties.Confidence.description: Level of confidence in the
  determination.
definitions.Eyeglasses.properties.Value.$ref: '#/definitions/Boolean'
definitions.Eyeglasses.properties.Value.description: Boolean value that indicates
  whether the face is wearing eye glasses or not.
definitions.Eyeglasses.type: object
definitions.Face.description: 'Describes the face properties such as the bounding
  box, face ID, image ID of the input image, and external image ID that you assigned. '
definitions.Face.properties.BoundingBox.$ref: '#/definitions/BoundingBox'
definitions.Face.properties.BoundingBox.description: Bounding box of the face.
definitions.Face.properties.Confidence.$ref: '#/definitions/Percent'
definitions.Face.properties.Confidence.description: Confidence level that the bounding
  box contains a face (and not a different object such as a tree).
definitions.Face.properties.ExternalImageId.$ref: '#/definitions/ExternalImageId'
definitions.Face.properties.ExternalImageId.description: Identifier that you assign
  to all the faces in the input image.
definitions.Face.properties.FaceId.$ref: '#/definitions/FaceId'
definitions.Face.properties.FaceId.description: Unique identifier that Amazon Rekognition
  assigns to the face.
definitions.Face.properties.ImageId.$ref: '#/definitions/ImageId'
definitions.Face.properties.ImageId.description: Unique identifier that Amazon Rekognition
  assigns to the input image.
definitions.Face.type: object
definitions.FaceDetail.description: Structure containing attributes of the face that
  the algorithm detected.
definitions.FaceDetail.properties.AgeRange.$ref: '#/definitions/AgeRange'
definitions.FaceDetail.properties.AgeRange.description: The estimated age range, in
  years, for the face. Low represents the lowest estimated age and High represents
  the highest estimated age.
definitions.FaceDetail.properties.Beard.$ref: '#/definitions/Beard'
definitions.FaceDetail.properties.Beard.description: Indicates whether or not the
  face has a beard, and the confidence level in the determination.
definitions.FaceDetail.properties.BoundingBox.$ref: '#/definitions/BoundingBox'
definitions.FaceDetail.properties.BoundingBox.description: Bounding box of the face.
definitions.FaceDetail.properties.Confidence.$ref: '#/definitions/Percent'
definitions.FaceDetail.properties.Confidence.description: Confidence level that the
  bounding box contains a face (and not a different object such as a tree).
definitions.FaceDetail.properties.Emotions.$ref: '#/definitions/Emotions'
definitions.FaceDetail.properties.Emotions.description: 'The emotions detected on
  the face, and the confidence level in the determination. For example, HAPPY, SAD,
  and ANGRY. '
definitions.FaceDetail.properties.Eyeglasses.$ref: '#/definitions/Eyeglasses'
definitions.FaceDetail.properties.Eyeglasses.description: Indicates whether or not
  the face is wearing eye glasses, and the confidence level in the determination.
definitions.FaceDetail.properties.EyesOpen.$ref: '#/definitions/EyeOpen'
definitions.FaceDetail.properties.EyesOpen.description: Indicates whether or not the
  eyes on the face are open, and the confidence level in the determination.
definitions.FaceDetail.properties.Gender.$ref: '#/definitions/Gender'
definitions.FaceDetail.properties.Gender.description: Gender of the face and the confidence
  level in the determination.
definitions.FaceDetail.properties.Landmarks.$ref: '#/definitions/Landmarks'
definitions.FaceDetail.properties.Landmarks.description: Indicates the location of
  landmarks on the face.
definitions.FaceDetail.properties.MouthOpen.$ref: '#/definitions/MouthOpen'
definitions.FaceDetail.properties.MouthOpen.description: Indicates whether or not
  the mouth on the face is open, and the confidence level in the determination.
definitions.FaceDetail.properties.Mustache.$ref: '#/definitions/Mustache'
definitions.FaceDetail.properties.Mustache.description: Indicates whether or not the
  face has a mustache, and the confidence level in the determination.
definitions.FaceDetail.properties.Pose.$ref: '#/definitions/Pose'
definitions.FaceDetail.properties.Pose.description: Indicates the pose of the face
  as determined by its pitch, roll, and yaw.
definitions.FaceDetail.properties.Quality.$ref: '#/definitions/ImageQuality'
definitions.FaceDetail.properties.Quality.description: Identifies image brightness
  and sharpness.
definitions.FaceDetail.properties.Smile.$ref: '#/definitions/Smile'
definitions.FaceDetail.properties.Smile.description: Indicates whether or not the
  face is smiling, and the confidence level in the determination.
definitions.FaceDetail.properties.Sunglasses.$ref: '#/definitions/Sunglasses'
definitions.FaceDetail.properties.Sunglasses.description: Indicates whether or not
  the face is wearing sunglasses, and the confidence level in the determination.
definitions.FaceDetail.type: object
definitions.FaceDetailList.items.$ref: '#/definitions/FaceDetail'
definitions.FaceDetailList.type: array
definitions.FaceId.pattern: '[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}'
definitions.FaceId.type: string
definitions.FaceIdList.items.$ref: '#/definitions/FaceId'
definitions.FaceIdList.maxItems: 4096
definitions.FaceIdList.minItems: 1
definitions.FaceIdList.type: array
definitions.FaceList.items.$ref: '#/definitions/Face'
definitions.FaceList.type: array
definitions.FaceMatch.description: Provides face metadata. In addition, it also provides
  the confidence in the match of this face with the input face.
definitions.FaceMatch.properties.Face.$ref: '#/definitions/Face'
definitions.FaceMatch.properties.Face.description: Describes the face properties such
  as the bounding box, face ID, image ID of the source image, and external image ID
  that you assigned.
definitions.FaceMatch.properties.Similarity.$ref: '#/definitions/Percent'
definitions.FaceMatch.properties.Similarity.description: Confidence in the match of
  this face with the input face.
definitions.FaceMatch.type: object
definitions.FaceMatchList.items.$ref: '#/definitions/FaceMatch'
definitions.FaceMatchList.type: array
definitions.FaceRecord.description: Object containing both the face metadata (stored
  in the back-end database) and facial attributes that are detected but aren't stored
  in the database.
definitions.FaceRecord.properties.Face.$ref: '#/definitions/Face'
definitions.FaceRecord.properties.Face.description: 'Describes the face properties
  such as the bounding box, face ID, image ID of the input image, and external image
  ID that you assigned. '
definitions.FaceRecord.properties.FaceDetail.$ref: '#/definitions/FaceDetail'
definitions.FaceRecord.properties.FaceDetail.description: Structure containing attributes
  of the face that the algorithm detected.
definitions.FaceRecord.type: object
definitions.FaceRecordList.items.$ref: '#/definitions/FaceRecord'
definitions.FaceRecordList.type: array
definitions.Float.format: float
definitions.Float.type: number
definitions.Gender.description: Gender of the face and the confidence level in the
  determination.
definitions.Gender.properties.Confidence.$ref: '#/definitions/Percent'
definitions.Gender.properties.Confidence.description: Level of confidence in the determination.
definitions.Gender.properties.Value.$ref: '#/definitions/GenderType'
definitions.Gender.properties.Value.description: Gender of the face.
definitions.Gender.type: object
definitions.GenderType.enum.length: 2
definitions.GenderType.enum[0]: Male
definitions.GenderType.enum[1]: Female
definitions.GenderType.type: string
definitions.GetCelebrityInfoRequest.properties.Id.$ref: '#/definitions/RekognitionUniqueId'
definitions.GetCelebrityInfoRequest.properties.Id.description: 'The ID for the celebrity.
  You get the celebrity ID from a call to the operation, which recognizes celebrities
  in an image. '
definitions.GetCelebrityInfoRequest.required.length: 1
definitions.GetCelebrityInfoRequest.required[0]: Id
definitions.GetCelebrityInfoRequest.type: object
definitions.GetCelebrityInfoResponse.properties.Name.$ref: '#/definitions/String'
definitions.GetCelebrityInfoResponse.properties.Name.description: The name of the
  celebrity.
definitions.GetCelebrityInfoResponse.properties.Urls.$ref: '#/definitions/Urls'
definitions.GetCelebrityInfoResponse.properties.Urls.description: 'An array of URLs
  pointing to additional celebrity information. '
definitions.GetCelebrityInfoResponse.type: object
definitions.Image.description: <p>Provides the input image either as bytes or an S3
  object.</p> <p>You pass image bytes to a Rekognition API operation by using the
  <code>Bytes</code> property. For example, you would use the <code>Bytes</code> property
  to pass an image loaded from a local file system. Image bytes passed by using the
  <code>Bytes</code> property must be base64-encoded. Your code may not need to encode
  image bytes if you are using an AWS SDK to call Rekognition API operations. For
  more information, see <a>example4</a>.</p> <p> You pass images stored in an S3 bucket
  to a Rekognition API operation by using the <code>S3Object</code> property. Images
  stored in an S3 bucket do not need to be base64-encoded.</p> <p>The region for the
  S3 bucket containing the S3 object must match the region you use for Amazon Rekognition
  operations.</p> <p>If you use the Amazon CLI to call Amazon Rekognition operations,
  passing image bytes using the Bytes property is not supported. You must first upload
  the image to an Amazon S3 bucket and then call the operation using the S3Object
  property.</p> <p>For Amazon Rekognition to process an S3 object, the user must have
  permission to access the S3 object. For more information, see <a>manage-access-resource-policies</a>.
  </p>
definitions.Image.properties.Bytes.$ref: '#/definitions/ImageBlob'
definitions.Image.properties.Bytes.description: Blob of image bytes up to 5 MBs.
definitions.Image.properties.S3Object.$ref: '#/definitions/S3Object'
definitions.Image.properties.S3Object.description: Identifies an S3 object as the
  image source.
definitions.Image.type: object
definitions.ImageBlob.maxLength: 5.24288e+06
definitions.ImageBlob.minLength: 1
definitions.ImageBlob.type: string
definitions.ImageId.pattern: '[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}'
definitions.ImageId.type: string
definitions.ImageQuality.description: 'Identifies face image brightness and sharpness. '
definitions.ImageQuality.properties.Brightness.$ref: '#/definitions/Float'
definitions.ImageQuality.properties.Brightness.description: Value representing brightness
  of the face. The service returns a value between 0 and 100 (inclusive). A higher
  value indicates a brighter face image.
definitions.ImageQuality.properties.Sharpness.$ref: '#/definitions/Float'
definitions.ImageQuality.properties.Sharpness.description: Value representing sharpness
  of the face. The service returns a value between 0 and 100 (inclusive). A higher
  value indicates a sharper face image.
definitions.ImageQuality.type: object
definitions.ImageTooLargeException.description: 'The input image size exceeds the
  allowed limit. For more information, see <a>limits</a>. '
definitions.ImageTooLargeException.type: object
definitions.IndexFacesRequest.example.CollectionId: myphotos
definitions.IndexFacesRequest.example.DetectionAttributes.length: 0
definitions.IndexFacesRequest.example.ExternalImageId: myphotoid
definitions.IndexFacesRequest.example.Image.S3Object.Bucket: mybucket
definitions.IndexFacesRequest.example.Image.S3Object.Name: myphoto
definitions.IndexFacesRequest.properties.CollectionId.$ref: '#/definitions/CollectionId'
definitions.IndexFacesRequest.properties.CollectionId.description: The ID of an existing
  collection to which you want to add the faces that are detected in the input images.
definitions.IndexFacesRequest.properties.DetectionAttributes.$ref: '#/definitions/Attributes'
definitions.IndexFacesRequest.properties.DetectionAttributes.description: '<p>An array
  of facial attributes that you want to be returned. This can be the default list
  of attributes or all attributes. If you don''t specify a value for <code>Attributes</code>
  or if you specify <code>["DEFAULT"]</code>, the API returns the following subset
  of facial attributes: <code>BoundingBox</code>, <code>Confidence</code>, <code>Pose</code>,
  <code>Quality</code> and <code>Landmarks</code>. If you provide <code>["ALL"]</code>,
  all facial attributes are returned but the operation will take longer to complete.</p>
  <p>If you provide both, <code>["ALL", "DEFAULT"]</code>, the service uses a logical
  AND operator to determine which attributes to return (in this case, all attributes).
  </p>'
definitions.IndexFacesRequest.properties.ExternalImageId.$ref: '#/definitions/ExternalImageId'
definitions.IndexFacesRequest.properties.ExternalImageId.description: ID you want
  to assign to all the faces detected in the image.
definitions.IndexFacesRequest.properties.Image.$ref: '#/definitions/Image'
definitions.IndexFacesRequest.properties.Image.description: The input image as bytes
  or an S3 object.
definitions.IndexFacesRequest.required.length: 2
definitions.IndexFacesRequest.required[0]: CollectionId
definitions.IndexFacesRequest.required[1]: Image
definitions.IndexFacesRequest.type: object
definitions.IndexFacesResponse.example.FaceRecords.length: 2
definitions.IndexFacesResponse.example.FaceRecords[0].Face.BoundingBox.Height: 0.33481482
definitions.IndexFacesResponse.example.FaceRecords[0].Face.BoundingBox.Left: 0.3188889
definitions.IndexFacesResponse.example.FaceRecords[0].Face.BoundingBox.Top: 0.49333334
definitions.IndexFacesResponse.example.FaceRecords[0].Face.BoundingBox.Width: 0.25
definitions.IndexFacesResponse.example.FaceRecords[0].Face.Confidence: 99.99912
definitions.IndexFacesResponse.example.FaceRecords[0].Face.FaceId: ff43d742-0c13-5d16-a3e8-03d3f58e980b
definitions.IndexFacesResponse.example.FaceRecords[0].Face.ImageId: 465f4e93-763e-51d0-b030-b9667a2d94b1
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.BoundingBox.Height: 0.33481482
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.BoundingBox.Left: 0.3188889
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.BoundingBox.Top: 0.49333334
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.BoundingBox.Width: 0.25
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Confidence: 99.99912
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks.length: 5
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[0].Type: eyeLeft
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[0].X: 0.39767647
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[0].Y: 0.6248346
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[1].Type: eyeRight
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[1].X: 0.48109365
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[1].Y: 0.6317117
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[2].Type: noseLeft
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[2].X: 0.4198624
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[2].Y: 0.71119404
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[3].Type: mouthDown
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[3].X: 0.40525302
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[3].Y: 0.7497701
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[4].Type: mouthUp
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[4].X: 0.4753249
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Landmarks[4].Y: 0.75585496
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Pose.Pitch: -9.713646
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Pose.Roll: 4.707281
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Pose.Yaw: -24.438663
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Quality.Brightness: 29.23359
definitions.IndexFacesResponse.example.FaceRecords[0].FaceDetail.Quality.Sharpness: 80
definitions.IndexFacesResponse.example.FaceRecords[1].Face.BoundingBox.Height: 0.32592592
definitions.IndexFacesResponse.example.FaceRecords[1].Face.BoundingBox.Left: 0.5144445
definitions.IndexFacesResponse.example.FaceRecords[1].Face.BoundingBox.Top: 0.15111111
definitions.IndexFacesResponse.example.FaceRecords[1].Face.BoundingBox.Width: 0.24444444
definitions.IndexFacesResponse.example.FaceRecords[1].Face.Confidence: 99.999504
definitions.IndexFacesResponse.example.FaceRecords[1].Face.FaceId: 8be04dba-4e58-520d-850e-9eae4af70eb2
definitions.IndexFacesResponse.example.FaceRecords[1].Face.ImageId: 465f4e93-763e-51d0-b030-b9667a2d94b1
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.BoundingBox.Height: 0.32592592
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.BoundingBox.Left: 0.5144445
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.BoundingBox.Top: 0.15111111
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.BoundingBox.Width: 0.24444444
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Confidence: 99.999504
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks.length: 5
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[0].Type: eyeLeft
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[0].X: 0.60068923
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[0].Y: 0.2908422
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[1].Type: eyeRight
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[1].X: 0.68081415
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[1].Y: 0.29609042
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[2].Type: noseLeft
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[2].X: 0.6395332
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[2].Y: 0.35225958
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[3].Type: mouthDown
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[3].X: 0.5892083
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[3].Y: 0.38689888
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[4].Type: mouthUp
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[4].X: 0.67456
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Landmarks[4].Y: 0.39412576
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Pose.Pitch: -4.6831384
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Pose.Roll: 2.102953
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Pose.Yaw: 6.7166553
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Quality.Brightness: 34.9517
definitions.IndexFacesResponse.example.FaceRecords[1].FaceDetail.Quality.Sharpness: 160
definitions.IndexFacesResponse.example.OrientationCorrection: ROTATE_0
definitions.IndexFacesResponse.properties.FaceRecords.$ref: '#/definitions/FaceRecordList'
definitions.IndexFacesResponse.properties.FaceRecords.description: 'An array of faces
  detected and added to the collection. For more information, see <a>howitworks-index-faces</a>. '
definitions.IndexFacesResponse.properties.OrientationCorrection.$ref: '#/definitions/OrientationCorrection'
definitions.IndexFacesResponse.properties.OrientationCorrection.description: <p>The
  orientation of the input image (counterclockwise direction). If your application
  displays the image, you can use this value to correct image orientation. The bounding
  box coordinates returned in <code>FaceRecords</code> represent face locations before
  the image orientation is corrected. </p> <note> <p>If the input image is in jpeg
  format, it might contain exchangeable image (Exif) metadata. If so, and the Exif
  metadata populates the orientation field, the value of <code>OrientationCorrection</code>
  is null and the bounding box coordinates in <code>FaceRecords</code> represent face
  locations after Exif metadata is used to correct the image orientation. Images in
  .png format don't contain Exif metadata.</p> </note>
definitions.IndexFacesResponse.type: object
definitions.InternalServerError.description: Amazon Rekognition experienced a service
  issue. Try your call again.
definitions.InternalServerError.type: object
definitions.InvalidImageFormatException.description: 'The provided image format is
  not supported. '
definitions.InvalidImageFormatException.type: object
definitions.InvalidPaginationTokenException.description: Pagination token in the request
  is not valid.
definitions.InvalidPaginationTokenException.type: object
definitions.InvalidParameterException.description: Input parameter violated a constraint.
  Validate your parameter before calling the API operation again.
definitions.InvalidParameterException.type: object
definitions.InvalidS3ObjectException.description: Amazon Rekognition is unable to
  access the S3 object specified in the request.
definitions.InvalidS3ObjectException.type: object
definitions.Label.description: Structure containing details about the detected label,
  including name, and level of confidence.
definitions.Label.properties.Confidence.$ref: '#/definitions/Percent'
definitions.Label.properties.Confidence.description: Level of confidence.
definitions.Label.properties.Name.$ref: '#/definitions/String'
definitions.Label.properties.Name.description: The name (label) of the object.
definitions.Label.type: object
definitions.Labels.items.$ref: '#/definitions/Label'
definitions.Labels.type: array
definitions.Landmark.description: Indicates the location of the landmark on the face.
definitions.Landmark.properties.Type.$ref: '#/definitions/LandmarkType'
definitions.Landmark.properties.Type.description: Type of the landmark.
definitions.Landmark.properties.X.$ref: '#/definitions/Float'
definitions.Landmark.properties.X.description: 'x-coordinate from the top left of
  the landmark expressed as the ratio of the width of the image. For example, if the
  images is 700x200 and the x-coordinate of the landmark is at 350 pixels, this value
  is 0.5. '
definitions.Landmark.properties.Y.$ref: '#/definitions/Float'
definitions.Landmark.properties.Y.description: y-coordinate from the top left of the
  landmark expressed as the ratio of the height of the image. For example, if the
  images is 700x200 and the y-coordinate of the landmark is at 100 pixels, this value
  is 0.5.
definitions.Landmark.type: object
definitions.LandmarkType.enum.length: 25
definitions.LandmarkType.enum[0]: eyeLeft
definitions.LandmarkType.enum[1]: eyeRight
definitions.LandmarkType.enum[2]: nose
definitions.LandmarkType.enum[3]: mouthLeft
definitions.LandmarkType.enum[4]: mouthRight
definitions.LandmarkType.enum[5]: leftEyeBrowLeft
definitions.LandmarkType.enum[6]: leftEyeBrowRight
definitions.LandmarkType.enum[7]: leftEyeBrowUp
definitions.LandmarkType.enum[8]: rightEyeBrowLeft
definitions.LandmarkType.enum[9]: rightEyeBrowRight
definitions.LandmarkType.enum[10]: rightEyeBrowUp
definitions.LandmarkType.enum[11]: leftEyeLeft
definitions.LandmarkType.enum[12]: leftEyeRight
definitions.LandmarkType.enum[13]: leftEyeUp
definitions.LandmarkType.enum[14]: leftEyeDown
definitions.LandmarkType.enum[15]: rightEyeLeft
definitions.LandmarkType.enum[16]: rightEyeRight
definitions.LandmarkType.enum[17]: rightEyeUp
definitions.LandmarkType.enum[18]: rightEyeDown
definitions.LandmarkType.enum[19]: noseLeft
definitions.LandmarkType.enum[20]: noseRight
definitions.LandmarkType.enum[21]: mouthUp
definitions.LandmarkType.enum[22]: mouthDown
definitions.LandmarkType.enum[23]: leftPupil
definitions.LandmarkType.enum[24]: rightPupil
definitions.LandmarkType.type: string
definitions.Landmarks.items.$ref: '#/definitions/Landmark'
definitions.Landmarks.type: array
definitions.ListCollectionsRequest.properties.MaxResults.$ref: '#/definitions/PageSize'
definitions.ListCollectionsRequest.properties.MaxResults.description: Maximum number
  of collection IDs to return.
definitions.ListCollectionsRequest.properties.NextToken.$ref: '#/definitions/PaginationToken'
definitions.ListCollectionsRequest.properties.NextToken.description: Pagination token
  from the previous response.
definitions.ListCollectionsRequest.type: object
definitions.ListCollectionsResponse.example.CollectionIds.length: 1
definitions.ListCollectionsResponse.example.CollectionIds[0]: myphotos
definitions.ListCollectionsResponse.properties.CollectionIds.$ref: '#/definitions/CollectionIdList'
definitions.ListCollectionsResponse.properties.CollectionIds.description: An array
  of collection IDs.
definitions.ListCollectionsResponse.properties.NextToken.$ref: '#/definitions/PaginationToken'
definitions.ListCollectionsResponse.properties.NextToken.description: If the result
  is truncated, the response provides a <code>NextToken</code> that you can use in
  the subsequent request to fetch the next set of collection IDs.
definitions.ListCollectionsResponse.type: object
definitions.ListFacesRequest.example.CollectionId: myphotos
definitions.ListFacesRequest.example.MaxResults: 20
definitions.ListFacesRequest.properties.CollectionId.$ref: '#/definitions/CollectionId'
definitions.ListFacesRequest.properties.CollectionId.description: ID of the collection
  from which to list the faces.
definitions.ListFacesRequest.properties.MaxResults.$ref: '#/definitions/PageSize'
definitions.ListFacesRequest.properties.MaxResults.description: Maximum number of
  faces to return.
definitions.ListFacesRequest.properties.NextToken.$ref: '#/definitions/PaginationToken'
definitions.ListFacesRequest.properties.NextToken.description: If the previous response
  was incomplete (because there is more data to retrieve), Amazon Rekognition returns
  a pagination token in the response. You can use this pagination token to retrieve
  the next set of faces.
definitions.ListFacesRequest.required.length: 1
definitions.ListFacesRequest.required[0]: CollectionId
definitions.ListFacesRequest.type: object
definitions.ListFacesResponse.example.Faces.length: 11
definitions.ListFacesResponse.example.Faces[0].BoundingBox.Height: 0.18
definitions.ListFacesResponse.example.Faces[0].BoundingBox.Left: 0.555556
definitions.ListFacesResponse.example.Faces[0].BoundingBox.Top: 0.336667
definitions.ListFacesResponse.example.Faces[0].BoundingBox.Width: 0.24
definitions.ListFacesResponse.example.Faces[0].Confidence: 100
definitions.ListFacesResponse.example.Faces[0].FaceId: 1c62e8b5-69a7-5b7d-b3cd-db4338a8a7e7
definitions.ListFacesResponse.example.Faces[0].ImageId: 147fdf82-7a71-52cf-819b-e786c7b9746e
definitions.ListFacesResponse.example.Faces[1].BoundingBox.Height: 0.165556
definitions.ListFacesResponse.example.Faces[1].BoundingBox.Left: 0.30963
definitions.ListFacesResponse.example.Faces[1].BoundingBox.Top: 0.706667
definitions.ListFacesResponse.example.Faces[1].BoundingBox.Width: 0.220741
definitions.ListFacesResponse.example.Faces[1].Confidence: 100
definitions.ListFacesResponse.example.Faces[1].FaceId: 29a75abe-397b-5101-ba4f-706783b2246c
definitions.ListFacesResponse.example.Faces[1].ImageId: 147fdf82-7a71-52cf-819b-e786c7b9746e
definitions.ListFacesResponse.example.Faces[2].BoundingBox.Height: 0.323442
definitions.ListFacesResponse.example.Faces[2].BoundingBox.Left: 0.323333
definitions.ListFacesResponse.example.Faces[2].BoundingBox.Top: 0.5
definitions.ListFacesResponse.example.Faces[2].BoundingBox.Width: 0.242222
definitions.ListFacesResponse.example.Faces[2].Confidence: 99.9983
definitions.ListFacesResponse.example.Faces[2].FaceId: 38271d79-7bc2-5efb-b752-398a8d575b85
definitions.ListFacesResponse.example.Faces[2].ImageId: d5631190-d039-54e4-b267-abd22c8647c5
definitions.ListFacesResponse.example.Faces[3].BoundingBox.Height: 0.0355556
definitions.ListFacesResponse.example.Faces[3].BoundingBox.Left: 0.373887
definitions.ListFacesResponse.example.Faces[3].BoundingBox.Top: 0.247778
definitions.ListFacesResponse.example.Faces[3].BoundingBox.Width: 0.0474777
definitions.ListFacesResponse.example.Faces[3].Confidence: 99.9921
definitions.ListFacesResponse.example.Faces[3].FaceId: 3b01bef0-c883-5654-ba42-d5ad28b720b3
definitions.ListFacesResponse.example.Faces[3].ImageId: 812d9f04-86f9-54fc-9275-8d0dcbcb6784
definitions.ListFacesResponse.example.Faces[4].BoundingBox.Height: 0.0533333
definitions.ListFacesResponse.example.Faces[4].BoundingBox.Left: 0.293769
definitions.ListFacesResponse.example.Faces[4].BoundingBox.Top: 0.356667
definitions.ListFacesResponse.example.Faces[4].BoundingBox.Width: 0.0712166
definitions.ListFacesResponse.example.Faces[4].Confidence: 99.9992
definitions.ListFacesResponse.example.Faces[4].FaceId: 4839a608-49d0-566c-8301-509d71b534d1
definitions.ListFacesResponse.example.Faces[4].ImageId: 812d9f04-86f9-54fc-9275-8d0dcbcb6784
definitions.ListFacesResponse.example.Faces[5].BoundingBox.Height: 0.324926
definitions.ListFacesResponse.example.Faces[5].BoundingBox.Left: 0.515556
definitions.ListFacesResponse.example.Faces[5].BoundingBox.Top: 0.151335
definitions.ListFacesResponse.example.Faces[5].BoundingBox.Width: 0.243333
definitions.ListFacesResponse.example.Faces[5].Confidence: 99.9995
definitions.ListFacesResponse.example.Faces[5].FaceId: 70008e50-75e4-55d0-8e80-363fb73b3a14
definitions.ListFacesResponse.example.Faces[5].ImageId: d5631190-d039-54e4-b267-abd22c8647c5
definitions.ListFacesResponse.example.Faces[6].BoundingBox.Height: 0.0377778
definitions.ListFacesResponse.example.Faces[6].BoundingBox.Left: 0.700297
definitions.ListFacesResponse.example.Faces[6].BoundingBox.Top: 0.187778
definitions.ListFacesResponse.example.Faces[6].BoundingBox.Width: 0.0504451
definitions.ListFacesResponse.example.Faces[6].Confidence: 99.9264
definitions.ListFacesResponse.example.Faces[6].FaceId: 7f5f88ed-d684-5a88-b0df-01e4a521552b
definitions.ListFacesResponse.example.Faces[6].ImageId: 812d9f04-86f9-54fc-9275-8d0dcbcb6784
definitions.ListFacesResponse.example.Faces[7].BoundingBox.Height: 0.0555556
definitions.ListFacesResponse.example.Faces[7].BoundingBox.Left: 0.139466
definitions.ListFacesResponse.example.Faces[7].BoundingBox.Top: 0.463333
definitions.ListFacesResponse.example.Faces[7].BoundingBox.Width: 0.0727003
definitions.ListFacesResponse.example.Faces[7].Confidence: 99.9947
definitions.ListFacesResponse.example.Faces[7].FaceId: 895b4e2c-81de-5902-a4bd-d1792bda00b2
definitions.ListFacesResponse.example.Faces[7].ImageId: 812d9f04-86f9-54fc-9275-8d0dcbcb6784
definitions.ListFacesResponse.example.Faces[8].BoundingBox.Height: 0.325926
definitions.ListFacesResponse.example.Faces[8].BoundingBox.Left: 0.514444
definitions.ListFacesResponse.example.Faces[8].BoundingBox.Top: 0.151111
definitions.ListFacesResponse.example.Faces[8].BoundingBox.Width: 0.244444
definitions.ListFacesResponse.example.Faces[8].Confidence: 99.9995
definitions.ListFacesResponse.example.Faces[8].FaceId: 8be04dba-4e58-520d-850e-9eae4af70eb2
definitions.ListFacesResponse.example.Faces[8].ImageId: 465f4e93-763e-51d0-b030-b9667a2d94b1
definitions.ListFacesResponse.example.Faces[9].BoundingBox.Height: 0.188889
definitions.ListFacesResponse.example.Faces[9].BoundingBox.Left: 0.378338
definitions.ListFacesResponse.example.Faces[9].BoundingBox.Top: 0.235556
definitions.ListFacesResponse.example.Faces[9].BoundingBox.Width: 0.252226
definitions.ListFacesResponse.example.Faces[9].Confidence: 99.9999
definitions.ListFacesResponse.example.Faces[9].FaceId: 908544ad-edc3-59df-8faf-6a87cc256cf5
definitions.ListFacesResponse.example.Faces[9].ImageId: 3c731605-d772-541a-a5e7-0375dbc68a07
definitions.ListFacesResponse.example.Faces[10].BoundingBox.Height: 0.334815
definitions.ListFacesResponse.example.Faces[10].BoundingBox.Left: 0.318889
definitions.ListFacesResponse.example.Faces[10].BoundingBox.Top: 0.493333
definitions.ListFacesResponse.example.Faces[10].BoundingBox.Width: 0.25
definitions.ListFacesResponse.example.Faces[10].Confidence: 99.9991
definitions.ListFacesResponse.example.Faces[10].FaceId: ff43d742-0c13-5d16-a3e8-03d3f58e980b
definitions.ListFacesResponse.example.Faces[10].ImageId: 465f4e93-763e-51d0-b030-b9667a2d94b1
definitions.ListFacesResponse.properties.Faces.$ref: '#/definitions/FaceList'
definitions.ListFacesResponse.properties.Faces.description: 'An array of <code>Face</code>
  objects. '
definitions.ListFacesResponse.properties.NextToken.$ref: '#/definitions/String'
definitions.ListFacesResponse.properties.NextToken.description: If the response is
  truncated, Amazon Rekognition returns this token that you can use in the subsequent
  request to retrieve the next set of faces.
definitions.ListFacesResponse.type: object
definitions.MaxFaces.maximum: 4096
definitions.MaxFaces.minimum: 1
definitions.MaxFaces.type: integer
definitions.ModerationLabel.description: Provides information about a single type
  of moderated content found in an image. Each type of moderated content has a label
  within a hierarchical taxonomy. For more information, see <a>image-moderation</a>.
definitions.ModerationLabel.properties.Confidence.$ref: '#/definitions/Percent'
definitions.ModerationLabel.properties.Confidence.description: <p>Specifies the confidence
  that Amazon Rekognition has that the label has been correctly identified.</p> <p>If
  you don't specify the <code>MinConfidence</code> parameter in the call to <code>DetectModerationLabels</code>,
  the operation returns labels with a confidence value greater than or equal to 50
  percent.</p>
definitions.ModerationLabel.properties.Name.$ref: '#/definitions/String'
definitions.ModerationLabel.properties.Name.description: The label name for the type
  of content detected in the image.
definitions.ModerationLabel.properties.ParentName.$ref: '#/definitions/String'
definitions.ModerationLabel.properties.ParentName.description: The name for the parent
  label. Labels at the top-level of the hierarchy have the parent label <code>""</code>.
definitions.ModerationLabel.type: object
definitions.ModerationLabels.items.$ref: '#/definitions/ModerationLabel'
definitions.ModerationLabels.type: array
definitions.MouthOpen.description: Indicates whether or not the mouth on the face
  is open, and the confidence level in the determination.
definitions.MouthOpen.properties.Confidence.$ref: '#/definitions/Percent'
definitions.MouthOpen.properties.Confidence.description: Level of confidence in the
  determination.
definitions.MouthOpen.properties.Value.$ref: '#/definitions/Boolean'
definitions.MouthOpen.properties.Value.description: Boolean value that indicates whether
  the mouth on the face is open or not.
definitions.MouthOpen.type: object
definitions.Mustache.description: Indicates whether or not the face has a mustache,
  and the confidence level in the determination.
definitions.Mustache.properties.Confidence.$ref: '#/definitions/Percent'
definitions.Mustache.properties.Confidence.description: Level of confidence in the
  determination.
definitions.Mustache.properties.Value.$ref: '#/definitions/Boolean'
definitions.Mustache.properties.Value.description: Boolean value that indicates whether
  the face has mustache or not.
definitions.Mustache.type: object
definitions.OrientationCorrection.enum.length: 4
definitions.OrientationCorrection.enum[0]: ROTATE_0
definitions.OrientationCorrection.enum[1]: ROTATE_90
definitions.OrientationCorrection.enum[2]: ROTATE_180
definitions.OrientationCorrection.enum[3]: ROTATE_270
definitions.OrientationCorrection.type: string
definitions.PageSize.maximum: 4096
definitions.PageSize.minimum: 0
definitions.PageSize.type: integer
definitions.PaginationToken.maxLength: 255
definitions.PaginationToken.type: string
definitions.Percent.format: float
definitions.Percent.maximum: 100
definitions.Percent.minimum: 0
definitions.Percent.type: number
definitions.Pose.description: Indicates the pose of the face as determined by its
  pitch, roll, and yaw.
definitions.Pose.properties.Pitch.$ref: '#/definitions/Degree'
definitions.Pose.properties.Pitch.description: Value representing the face rotation
  on the pitch axis.
definitions.Pose.properties.Roll.$ref: '#/definitions/Degree'
definitions.Pose.properties.Roll.description: Value representing the face rotation
  on the roll axis.
definitions.Pose.properties.Yaw.$ref: '#/definitions/Degree'
definitions.Pose.properties.Yaw.description: Value representing the face rotation
  on the yaw axis.
definitions.Pose.type: object
definitions.ProvisionedThroughputExceededException.description: The number of requests
  exceeded your throughput limit. If you want to increase this limit, contact Amazon
  Rekognition.
definitions.ProvisionedThroughputExceededException.type: object
definitions.RecognizeCelebritiesRequest.properties.Image.$ref: '#/definitions/Image'
definitions.RecognizeCelebritiesRequest.properties.Image.description: The input image
  to use for celebrity recognition.
definitions.RecognizeCelebritiesRequest.required.length: 1
definitions.RecognizeCelebritiesRequest.required[0]: Image
definitions.RecognizeCelebritiesRequest.type: object
definitions.RecognizeCelebritiesResponse.properties.CelebrityFaces.$ref: '#/definitions/CelebrityList'
definitions.RecognizeCelebritiesResponse.properties.CelebrityFaces.description: Details
  about each celebrity found in the image. Amazon Rekognition can detect a maximum
  of 15 celebrities in an image.
definitions.RecognizeCelebritiesResponse.properties.OrientationCorrection.$ref: '#/definitions/OrientationCorrection'
definitions.RecognizeCelebritiesResponse.properties.OrientationCorrection.description: <p>The
  orientation of the input image (counterclockwise direction). If your application
  displays the image, you can use this value to correct the orientation. The bounding
  box coordinates returned in <code>CelebrityFaces</code> and <code>UnrecognizedFaces</code>
  represent face locations before the image orientation is corrected. </p> <note>
  <p>If the input image is in .jpeg format, it might contain exchangeable image (Exif)
  metadata that includes the image's orientation. If so, and the Exif metadata for
  the input image populates the orientation field, the value of <code>OrientationCorrection</code>
  is null and the <code>CelebrityFaces</code> and <code>UnrecognizedFaces</code> bounding
  box coordinates represent face locations after Exif metadata is used to correct
  the image orientation. Images in .png format don't contain Exif metadata. </p> </note>
definitions.RecognizeCelebritiesResponse.properties.UnrecognizedFaces.$ref: '#/definitions/ComparedFaceList'
definitions.RecognizeCelebritiesResponse.properties.UnrecognizedFaces.description: Details
  about each unrecognized face in the image.
definitions.RecognizeCelebritiesResponse.type: object
definitions.RekognitionUniqueId.pattern: '[0-9A-Za-z]*'
definitions.RekognitionUniqueId.type: string
definitions.ResourceAlreadyExistsException.description: A collection with the specified
  ID already exists.
definitions.ResourceAlreadyExistsException.type: object
definitions.ResourceNotFoundException.description: Collection specified in the request
  is not found.
definitions.ResourceNotFoundException.type: object
definitions.S3Bucket.maxLength: 255
definitions.S3Bucket.minLength: 3
definitions.S3Bucket.pattern: '[0-9A-Za-z\.\-_]*'
definitions.S3Bucket.type: string
definitions.S3Object.description: <p>Provides the S3 bucket name and object name.</p>
  <p>The region for the S3 bucket containing the S3 object must match the region you
  use for Amazon Rekognition operations.</p> <p>For Amazon Rekognition to process
  an S3 object, the user must have permission to access the S3 object. For more information,
  see <a>manage-access-resource-policies</a>. </p>
definitions.S3Object.properties.Bucket.$ref: '#/definitions/S3Bucket'
definitions.S3Object.properties.Bucket.description: Name of the S3 bucket.
definitions.S3Object.properties.Name.$ref: '#/definitions/S3ObjectName'
definitions.S3Object.properties.Name.description: S3 object key name.
definitions.S3Object.properties.Version.$ref: '#/definitions/S3ObjectVersion'
definitions.S3Object.properties.Version.description: 'If the bucket is versioning
  enabled, you can specify the object version. '
definitions.S3Object.type: object
definitions.S3ObjectName.maxLength: 1024
definitions.S3ObjectName.minLength: 1
definitions.S3ObjectName.type: string
definitions.S3ObjectVersion.maxLength: 1024
definitions.S3ObjectVersion.minLength: 1
definitions.S3ObjectVersion.type: string
definitions.SearchFacesByImageRequest.example.CollectionId: myphotos
definitions.SearchFacesByImageRequest.example.FaceMatchThreshold: 95
definitions.SearchFacesByImageRequest.example.Image.S3Object.Bucket: mybucket
definitions.SearchFacesByImageRequest.example.Image.S3Object.Name: myphoto
definitions.SearchFacesByImageRequest.example.MaxFaces: 5
definitions.SearchFacesByImageRequest.properties.CollectionId.$ref: '#/definitions/CollectionId'
definitions.SearchFacesByImageRequest.properties.CollectionId.description: ID of the
  collection to search.
definitions.SearchFacesByImageRequest.properties.FaceMatchThreshold.$ref: '#/definitions/Percent'
definitions.SearchFacesByImageRequest.properties.FaceMatchThreshold.description: (Optional)
  Specifies the minimum confidence in the face match to return. For example, don't
  return any matches where confidence in matches is less than 70%.
definitions.SearchFacesByImageRequest.properties.Image.$ref: '#/definitions/Image'
definitions.SearchFacesByImageRequest.properties.Image.description: The input image
  as bytes or an S3 object.
definitions.SearchFacesByImageRequest.properties.MaxFaces.$ref: '#/definitions/MaxFaces'
definitions.SearchFacesByImageRequest.properties.MaxFaces.description: Maximum number
  of faces to return. The operation returns the maximum number of faces with the highest
  confidence in the match.
definitions.SearchFacesByImageRequest.required.length: 2
definitions.SearchFacesByImageRequest.required[0]: CollectionId
definitions.SearchFacesByImageRequest.required[1]: Image
definitions.SearchFacesByImageRequest.type: object
definitions.SearchFacesByImageResponse.example.FaceMatches.length: 1
definitions.SearchFacesByImageResponse.example.FaceMatches[0].Face.BoundingBox.Height: 0.323442
definitions.SearchFacesByImageResponse.example.FaceMatches[0].Face.BoundingBox.Left: 0.323333
definitions.SearchFacesByImageResponse.example.FaceMatches[0].Face.BoundingBox.Top: 0.5
definitions.SearchFacesByImageResponse.example.FaceMatches[0].Face.BoundingBox.Width: 0.242222
definitions.SearchFacesByImageResponse.example.FaceMatches[0].Face.Confidence: 99.9983
definitions.SearchFacesByImageResponse.example.FaceMatches[0].Face.FaceId: 38271d79-7bc2-5efb-b752-398a8d575b85
definitions.SearchFacesByImageResponse.example.FaceMatches[0].Face.ImageId: d5631190-d039-54e4-b267-abd22c8647c5
definitions.SearchFacesByImageResponse.example.FaceMatches[0].Similarity: 99.97037
definitions.SearchFacesByImageResponse.example.SearchedFaceBoundingBox.Height: 0.33481482
definitions.SearchFacesByImageResponse.example.SearchedFaceBoundingBox.Left: 0.3188889
definitions.SearchFacesByImageResponse.example.SearchedFaceBoundingBox.Top: 0.49333334
definitions.SearchFacesByImageResponse.example.SearchedFaceBoundingBox.Width: 0.25
definitions.SearchFacesByImageResponse.example.SearchedFaceConfidence: 99.99912
definitions.SearchFacesByImageResponse.properties.FaceMatches.$ref: '#/definitions/FaceMatchList'
definitions.SearchFacesByImageResponse.properties.FaceMatches.description: An array
  of faces that match the input face, along with the confidence in the match.
definitions.SearchFacesByImageResponse.properties.SearchedFaceBoundingBox.$ref: '#/definitions/BoundingBox'
definitions.SearchFacesByImageResponse.properties.SearchedFaceBoundingBox.description: The
  bounding box around the face in the input image that Amazon Rekognition used for
  the search.
definitions.SearchFacesByImageResponse.properties.SearchedFaceConfidence.$ref: '#/definitions/Percent'
definitions.SearchFacesByImageResponse.properties.SearchedFaceConfidence.description: The
  level of confidence that the <code>searchedFaceBoundingBox</code>, contains a face.
definitions.SearchFacesByImageResponse.type: object
definitions.SearchFacesRequest.example.CollectionId: myphotos
definitions.SearchFacesRequest.example.FaceId: 70008e50-75e4-55d0-8e80-363fb73b3a14
definitions.SearchFacesRequest.example.FaceMatchThreshold: 90
definitions.SearchFacesRequest.example.MaxFaces: 10
definitions.SearchFacesRequest.properties.CollectionId.$ref: '#/definitions/CollectionId'
definitions.SearchFacesRequest.properties.CollectionId.description: ID of the collection
  the face belongs to.
definitions.SearchFacesRequest.properties.FaceId.$ref: '#/definitions/FaceId'
definitions.SearchFacesRequest.properties.FaceId.description: ID of a face to find
  matches for in the collection.
definitions.SearchFacesRequest.properties.FaceMatchThreshold.$ref: '#/definitions/Percent'
definitions.SearchFacesRequest.properties.FaceMatchThreshold.description: Optional
  value specifying the minimum confidence in the face match to return. For example,
  don't return any matches where confidence in matches is less than 70%.
definitions.SearchFacesRequest.properties.MaxFaces.$ref: '#/definitions/MaxFaces'
definitions.SearchFacesRequest.properties.MaxFaces.description: Maximum number of
  faces to return. The operation returns the maximum number of faces with the highest
  confidence in the match.
definitions.SearchFacesRequest.required.length: 2
definitions.SearchFacesRequest.required[0]: CollectionId
definitions.SearchFacesRequest.required[1]: FaceId
definitions.SearchFacesRequest.type: object
definitions.SearchFacesResponse.example.FaceMatches.length: 3
definitions.SearchFacesResponse.example.FaceMatches[0].Face.BoundingBox.Height: 0.325926
definitions.SearchFacesResponse.example.FaceMatches[0].Face.BoundingBox.Left: 0.514444
definitions.SearchFacesResponse.example.FaceMatches[0].Face.BoundingBox.Top: 0.151111
definitions.SearchFacesResponse.example.FaceMatches[0].Face.BoundingBox.Width: 0.244444
definitions.SearchFacesResponse.example.FaceMatches[0].Face.Confidence: 99.9995
definitions.SearchFacesResponse.example.FaceMatches[0].Face.FaceId: 8be04dba-4e58-520d-850e-9eae4af70eb2
definitions.SearchFacesResponse.example.FaceMatches[0].Face.ImageId: 465f4e93-763e-51d0-b030-b9667a2d94b1
definitions.SearchFacesResponse.example.FaceMatches[0].Similarity: 99.97222
definitions.SearchFacesResponse.example.FaceMatches[1].Face.BoundingBox.Height: 0.165556
definitions.SearchFacesResponse.example.FaceMatches[1].Face.BoundingBox.Left: 0.30963
definitions.SearchFacesResponse.example.FaceMatches[1].Face.BoundingBox.Top: 0.706667
definitions.SearchFacesResponse.example.FaceMatches[1].Face.BoundingBox.Width: 0.220741
definitions.SearchFacesResponse.example.FaceMatches[1].Face.Confidence: 100
definitions.SearchFacesResponse.example.FaceMatches[1].Face.FaceId: 29a75abe-397b-5101-ba4f-706783b2246c
definitions.SearchFacesResponse.example.FaceMatches[1].Face.ImageId: 147fdf82-7a71-52cf-819b-e786c7b9746e
definitions.SearchFacesResponse.example.FaceMatches[1].Similarity: 97.04155
definitions.SearchFacesResponse.example.FaceMatches[2].Face.BoundingBox.Height: 0.188889
definitions.SearchFacesResponse.example.FaceMatches[2].Face.BoundingBox.Left: 0.378338
definitions.SearchFacesResponse.example.FaceMatches[2].Face.BoundingBox.Top: 0.235556
definitions.SearchFacesResponse.example.FaceMatches[2].Face.BoundingBox.Width: 0.252226
definitions.SearchFacesResponse.example.FaceMatches[2].Face.Confidence: 99.9999
definitions.SearchFacesResponse.example.FaceMatches[2].Face.FaceId: 908544ad-edc3-59df-8faf-6a87cc256cf5
definitions.SearchFacesResponse.example.FaceMatches[2].Face.ImageId: 3c731605-d772-541a-a5e7-0375dbc68a07
definitions.SearchFacesResponse.example.FaceMatches[2].Similarity: 95.945206
definitions.SearchFacesResponse.example.SearchedFaceId: 70008e50-75e4-55d0-8e80-363fb73b3a14
definitions.SearchFacesResponse.properties.FaceMatches.$ref: '#/definitions/FaceMatchList'
definitions.SearchFacesResponse.properties.FaceMatches.description: An array of faces
  that matched the input face, along with the confidence in the match.
definitions.SearchFacesResponse.properties.SearchedFaceId.$ref: '#/definitions/FaceId'
definitions.SearchFacesResponse.properties.SearchedFaceId.description: ID of the face
  that was searched for matches in a collection.
definitions.SearchFacesResponse.type: object
definitions.Smile.description: Indicates whether or not the face is smiling, and the
  confidence level in the determination.
definitions.Smile.properties.Confidence.$ref: '#/definitions/Percent'
definitions.Smile.properties.Confidence.description: Level of confidence in the determination.
definitions.Smile.properties.Value.$ref: '#/definitions/Boolean'
definitions.Smile.properties.Value.description: Boolean value that indicates whether
  the face is smiling or not.
definitions.Smile.type: object
definitions.String.type: string
definitions.Sunglasses.description: Indicates whether or not the face is wearing sunglasses,
  and the confidence level in the determination.
definitions.Sunglasses.properties.Confidence.$ref: '#/definitions/Percent'
definitions.Sunglasses.properties.Confidence.description: Level of confidence in the
  determination.
definitions.Sunglasses.properties.Value.$ref: '#/definitions/Boolean'
definitions.Sunglasses.properties.Value.description: Boolean value that indicates
  whether the face is wearing sunglasses or not.
definitions.Sunglasses.type: object
definitions.ThrottlingException.description: Amazon Rekognition is temporarily unable
  to process the request. Try your call again.
definitions.ThrottlingException.type: object
definitions.UInteger.minimum: 0
definitions.UInteger.type: integer
definitions.Url.type: string
definitions.Urls.items.$ref: '#/definitions/Url'
definitions.Urls.type: array
externalDocs.description: Amazon Web Services documentation
externalDocs.url: https://aws.amazon.com/rekognition/
host: rekognition.amazonaws.com
info.contact.email: mike.ralphson@gmail.com
info.contact.name: Mike Ralphson
info.contact.url: https://github.com/mermade/aws2openapi
info.description: This is the Amazon Rekognition API reference.
info.license.name: Apache 2.0 License
info.license.url: http://www.apache.org/licenses/
info.termsOfService: https://aws.amazon.com/service-terms/
info.title: Amazon Rekognition
info.version: 2016-06-27
info.x-apiClientRegistration.url: https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?nc2=h_ct
info.x-apisguru-categories.length: 1
info.x-apisguru-categories[0]: cloud
info.x-logo.backgroundColor: '#FFFFFF'
info.x-logo.url: https://api.apis.guru/v2/cache/logo/https_media.amazonwebservices.com_blog_2007_big_pbaws_logo_300px.jpg
info.x-origin.length: 1
info.x-origin[0].contentType: application/json
info.x-origin[0].converter.url: https://github.com/mermade/aws2openapi
info.x-origin[0].converter.version: 1.0.0
info.x-origin[0].url: https://raw.githubusercontent.com/aws/aws-sdk-js/master/apis/rekognition-2016-06-27.normal.json
info.x-origin[0].x-apisguru-direct: true
info.x-preferred: true
info.x-providerName: amazonaws.com
info.x-release: v4
info.x-serviceName: rekognition
parameters.Action.in: header
parameters.Action.name: Action
parameters.Action.required: true
parameters.Action.type: string
parameters.Version.in: header
parameters.Version.name: Version
parameters.Version.required: true
parameters.Version.type: string
parameters.X-Amz-Algorithm.in: header
parameters.X-Amz-Algorithm.name: X-Amz-Algorithm
parameters.X-Amz-Algorithm.required: false
parameters.X-Amz-Algorithm.type: string
parameters.X-Amz-Content-Sha256.in: header
parameters.X-Amz-Content-Sha256.name: X-Amz-Content-Sha256
parameters.X-Amz-Content-Sha256.required: false
parameters.X-Amz-Content-Sha256.type: string
parameters.X-Amz-Credential.in: header
parameters.X-Amz-Credential.name: X-Amz-Credential
parameters.X-Amz-Credential.required: false
parameters.X-Amz-Credential.type: string
parameters.X-Amz-Date.in: header
parameters.X-Amz-Date.name: X-Amz-Date
parameters.X-Amz-Date.required: false
parameters.X-Amz-Date.type: string
parameters.X-Amz-Security-Token.in: header
parameters.X-Amz-Security-Token.name: X-Amz-Security-Token
parameters.X-Amz-Security-Token.required: false
parameters.X-Amz-Security-Token.type: string
parameters.X-Amz-Signature.in: header
parameters.X-Amz-Signature.name: X-Amz-Signature
parameters.X-Amz-Signature.required: false
parameters.X-Amz-Signature.type: string
parameters.X-Amz-SignedHeaders.in: header
parameters.X-Amz-SignedHeaders.name: X-Amz-SignedHeaders
parameters.X-Amz-SignedHeaders.required: false
parameters.X-Amz-SignedHeaders.type: string
paths./#CreateCollection.parameters.length: 9
paths./#CreateCollection.parameters[0].$ref: '#/parameters/Action'
paths./#CreateCollection.parameters[1].$ref: '#/parameters/Version'
paths./#CreateCollection.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./#CreateCollection.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./#CreateCollection.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./#CreateCollection.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./#CreateCollection.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./#CreateCollection.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./#CreateCollection.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./#CreateCollection.post.description: <p>Creates a collection in an AWS Region.
  You can add faces to the collection using the operation. </p> <p>For example, you
  might create collections, one for each of your application users. A user can then
  index faces using the <code>IndexFaces</code> operation and persist results in a
  specific collection. Then, a user can search the collection for faces in the user-specific
  container. </p> <note> <p>Collection names are case-sensitive.</p> </note> <p>For
  an example, see <a>example1</a>. </p> <p>This operation requires permissions to
  perform the <code>rekognition:CreateCollection</code> action.</p>
paths./#CreateCollection.post.operationId: CreateCollection
paths./#CreateCollection.post.parameters.length: 1
paths./#CreateCollection.post.parameters[0].in: body
paths./#CreateCollection.post.parameters[0].name: body
paths./#CreateCollection.post.parameters[0].required: true
paths./#CreateCollection.post.parameters[0].schema.$ref: '#/definitions/CreateCollectionRequest'
paths./#CreateCollection.post.responses.200.description: Success
paths./#CreateCollection.post.responses.200.schema.$ref: '#/definitions/CreateCollectionResponse'
paths./#CreateCollection.post.responses.480.description: InvalidParameterException
paths./#CreateCollection.post.responses.480.schema.$ref: '#/definitions/InvalidParameterException'
paths./#CreateCollection.post.responses.481.description: AccessDeniedException
paths./#CreateCollection.post.responses.481.schema.$ref: '#/definitions/AccessDeniedException'
paths./#CreateCollection.post.responses.482.description: InternalServerError
paths./#CreateCollection.post.responses.482.schema.$ref: '#/definitions/InternalServerError'
paths./#CreateCollection.post.responses.483.description: ThrottlingException
paths./#CreateCollection.post.responses.483.schema.$ref: '#/definitions/ThrottlingException'
paths./#CreateCollection.post.responses.484.description: ProvisionedThroughputExceededException
paths./#CreateCollection.post.responses.484.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./#CreateCollection.post.responses.485.description: ResourceAlreadyExistsException
paths./#CreateCollection.post.responses.485.schema.$ref: '#/definitions/ResourceAlreadyExistsException'
paths./#DeleteCollection.parameters.length: 9
paths./#DeleteCollection.parameters[0].$ref: '#/parameters/Action'
paths./#DeleteCollection.parameters[1].$ref: '#/parameters/Version'
paths./#DeleteCollection.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./#DeleteCollection.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./#DeleteCollection.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./#DeleteCollection.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./#DeleteCollection.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./#DeleteCollection.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./#DeleteCollection.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./#DeleteCollection.post.description: <p>Deletes the specified collection. Note
  that this operation removes all faces in the collection. For an example, see <a>example1</a>.</p>
  <p>This operation requires permissions to perform the <code>rekognition:DeleteCollection</code>
  action.</p>
paths./#DeleteCollection.post.operationId: DeleteCollection
paths./#DeleteCollection.post.parameters.length: 1
paths./#DeleteCollection.post.parameters[0].in: body
paths./#DeleteCollection.post.parameters[0].name: body
paths./#DeleteCollection.post.parameters[0].required: true
paths./#DeleteCollection.post.parameters[0].schema.$ref: '#/definitions/DeleteCollectionRequest'
paths./#DeleteCollection.post.responses.200.description: Success
paths./#DeleteCollection.post.responses.200.schema.$ref: '#/definitions/DeleteCollectionResponse'
paths./#DeleteCollection.post.responses.480.description: InvalidParameterException
paths./#DeleteCollection.post.responses.480.schema.$ref: '#/definitions/InvalidParameterException'
paths./#DeleteCollection.post.responses.481.description: AccessDeniedException
paths./#DeleteCollection.post.responses.481.schema.$ref: '#/definitions/AccessDeniedException'
paths./#DeleteCollection.post.responses.482.description: InternalServerError
paths./#DeleteCollection.post.responses.482.schema.$ref: '#/definitions/InternalServerError'
paths./#DeleteCollection.post.responses.483.description: ThrottlingException
paths./#DeleteCollection.post.responses.483.schema.$ref: '#/definitions/ThrottlingException'
paths./#DeleteCollection.post.responses.484.description: ProvisionedThroughputExceededException
paths./#DeleteCollection.post.responses.484.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./#DeleteCollection.post.responses.485.description: ResourceNotFoundException
paths./#DeleteCollection.post.responses.485.schema.$ref: '#/definitions/ResourceNotFoundException'
paths./#DeleteFaces.parameters.length: 9
paths./#DeleteFaces.parameters[0].$ref: '#/parameters/Action'
paths./#DeleteFaces.parameters[1].$ref: '#/parameters/Version'
paths./#DeleteFaces.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./#DeleteFaces.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./#DeleteFaces.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./#DeleteFaces.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./#DeleteFaces.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./#DeleteFaces.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./#DeleteFaces.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./#DeleteFaces.post.description: <p>Deletes faces from a collection. You specify
  a collection ID and an array of face IDs to remove from the collection.</p> <p>This
  operation requires permissions to perform the <code>rekognition:DeleteFaces</code>
  action.</p>
paths./#DeleteFaces.post.operationId: DeleteFaces
paths./#DeleteFaces.post.parameters.length: 1
paths./#DeleteFaces.post.parameters[0].in: body
paths./#DeleteFaces.post.parameters[0].name: body
paths./#DeleteFaces.post.parameters[0].required: true
paths./#DeleteFaces.post.parameters[0].schema.$ref: '#/definitions/DeleteFacesRequest'
paths./#DeleteFaces.post.responses.200.description: Success
paths./#DeleteFaces.post.responses.200.schema.$ref: '#/definitions/DeleteFacesResponse'
paths./#DeleteFaces.post.responses.480.description: InvalidParameterException
paths./#DeleteFaces.post.responses.480.schema.$ref: '#/definitions/InvalidParameterException'
paths./#DeleteFaces.post.responses.481.description: AccessDeniedException
paths./#DeleteFaces.post.responses.481.schema.$ref: '#/definitions/AccessDeniedException'
paths./#DeleteFaces.post.responses.482.description: InternalServerError
paths./#DeleteFaces.post.responses.482.schema.$ref: '#/definitions/InternalServerError'
paths./#DeleteFaces.post.responses.483.description: ThrottlingException
paths./#DeleteFaces.post.responses.483.schema.$ref: '#/definitions/ThrottlingException'
paths./#DeleteFaces.post.responses.484.description: ProvisionedThroughputExceededException
paths./#DeleteFaces.post.responses.484.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./#DeleteFaces.post.responses.485.description: ResourceNotFoundException
paths./#DeleteFaces.post.responses.485.schema.$ref: '#/definitions/ResourceNotFoundException'
paths./#DetectFaces.parameters.length: 9
paths./#DetectFaces.parameters[0].$ref: '#/parameters/Action'
paths./#DetectFaces.parameters[1].$ref: '#/parameters/Version'
paths./#DetectFaces.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./#DetectFaces.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./#DetectFaces.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./#DetectFaces.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./#DetectFaces.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./#DetectFaces.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./#DetectFaces.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./#DetectFaces.post.description: <p>Detects faces within an image (JPEG or PNG)
  that is provided as input.</p> <p> For each face detected, the operation returns
  face details including a bounding box of the face, a confidence value (that the
  bounding box contains a face), and a fixed set of attributes such as facial landmarks
  (for example, coordinates of eye and mouth), gender, presence of beard, sunglasses,
  etc. </p> <p>The face-detection algorithm is most effective on frontal faces. For
  non-frontal or obscured faces, the algorithm may not detect the faces or might detect
  faces with lower confidence. </p> <note> <p>This is a stateless API operation. That
  is, the operation does not persist any data.</p> </note> <p>For an example, see
  <a>get-started-exercise-detect-faces</a>.</p> <p>This operation requires permissions
  to perform the <code>rekognition:DetectFaces</code> action. </p>
paths./#DetectFaces.post.operationId: DetectFaces
paths./#DetectFaces.post.parameters.length: 1
paths./#DetectFaces.post.parameters[0].in: body
paths./#DetectFaces.post.parameters[0].name: body
paths./#DetectFaces.post.parameters[0].required: true
paths./#DetectFaces.post.parameters[0].schema.$ref: '#/definitions/DetectFacesRequest'
paths./#DetectFaces.post.responses.200.description: Success
paths./#DetectFaces.post.responses.200.schema.$ref: '#/definitions/DetectFacesResponse'
paths./#DetectFaces.post.responses.480.description: InvalidS3ObjectException
paths./#DetectFaces.post.responses.480.schema.$ref: '#/definitions/InvalidS3ObjectException'
paths./#DetectFaces.post.responses.481.description: InvalidParameterException
paths./#DetectFaces.post.responses.481.schema.$ref: '#/definitions/InvalidParameterException'
paths./#DetectFaces.post.responses.482.description: ImageTooLargeException
paths./#DetectFaces.post.responses.482.schema.$ref: '#/definitions/ImageTooLargeException'
paths./#DetectFaces.post.responses.483.description: AccessDeniedException
paths./#DetectFaces.post.responses.483.schema.$ref: '#/definitions/AccessDeniedException'
paths./#DetectFaces.post.responses.484.description: InternalServerError
paths./#DetectFaces.post.responses.484.schema.$ref: '#/definitions/InternalServerError'
paths./#DetectFaces.post.responses.485.description: ThrottlingException
paths./#DetectFaces.post.responses.485.schema.$ref: '#/definitions/ThrottlingException'
paths./#DetectFaces.post.responses.486.description: ProvisionedThroughputExceededException
paths./#DetectFaces.post.responses.486.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./#DetectFaces.post.responses.487.description: InvalidImageFormatException
paths./#DetectFaces.post.responses.487.schema.$ref: '#/definitions/InvalidImageFormatException'
paths./#DetectLabels.parameters.length: 9
paths./#DetectLabels.parameters[0].$ref: '#/parameters/Action'
paths./#DetectLabels.parameters[1].$ref: '#/parameters/Version'
paths./#DetectLabels.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./#DetectLabels.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./#DetectLabels.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./#DetectLabels.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./#DetectLabels.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./#DetectLabels.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./#DetectLabels.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./#DetectLabels.post.description: '<p>Detects instances of real-world labels
  within an image (JPEG or PNG) provided as input. This includes objects like flower,
  tree, and table; events like wedding, graduation, and birthday party; and concepts
  like landscape, evening, and nature. For an example, see <a>get-started-exercise-detect-labels</a>.</p>
  <p> For each object, scene, and concept the API returns one or more labels. Each
  label provides the object name, and the level of confidence that the image contains
  the object. For example, suppose the input image has a lighthouse, the sea, and
  a rock. The response will include all three labels, one for each object. </p> <p>
  <code>{Name: lighthouse, Confidence: 98.4629}</code> </p> <p> <code>{Name: rock,Confidence:
  79.2097}</code> </p> <p> <code> {Name: sea,Confidence: 75.061}</code> </p> <p> In
  the preceding example, the operation returns one label for each of the three objects.
  The operation can also return multiple labels for the same object in the image.
  For example, if the input image shows a flower (for example, a tulip), the operation
  might return the following three labels. </p> <p> <code>{Name: flower,Confidence:
  99.0562}</code> </p> <p> <code>{Name: plant,Confidence: 99.0562}</code> </p> <p>
  <code>{Name: tulip,Confidence: 99.0562}</code> </p> <p>In this example, the detection
  algorithm more precisely identifies the flower as a tulip.</p> <p>You can provide
  the input image as an S3 object or as base64-encoded bytes. In response, the API
  returns an array of labels. In addition, the response also includes the orientation
  correction. Optionally, you can specify <code>MinConfidence</code> to control the
  confidence threshold for the labels returned. The default is 50%. You can also add
  the <code>MaxLabels</code> parameter to limit the number of labels returned. </p>
  <note> <p>If the object detected is a person, the operation doesn''t provide the
  same facial details that the <a>DetectFaces</a> operation provides.</p> </note>
  <p>This is a stateless API operation. That is, the operation does not persist any
  data.</p> <p>This operation requires permissions to perform the <code>rekognition:DetectLabels</code>
  action. </p>'
paths./#DetectLabels.post.operationId: DetectLabels
paths./#DetectLabels.post.parameters.length: 1
paths./#DetectLabels.post.parameters[0].in: body
paths./#DetectLabels.post.parameters[0].name: body
paths./#DetectLabels.post.parameters[0].required: true
paths./#DetectLabels.post.parameters[0].schema.$ref: '#/definitions/DetectLabelsRequest'
paths./#DetectLabels.post.responses.200.description: Success
paths./#DetectLabels.post.responses.200.schema.$ref: '#/definitions/DetectLabelsResponse'
paths./#DetectLabels.post.responses.480.description: InvalidS3ObjectException
paths./#DetectLabels.post.responses.480.schema.$ref: '#/definitions/InvalidS3ObjectException'
paths./#DetectLabels.post.responses.481.description: InvalidParameterException
paths./#DetectLabels.post.responses.481.schema.$ref: '#/definitions/InvalidParameterException'
paths./#DetectLabels.post.responses.482.description: ImageTooLargeException
paths./#DetectLabels.post.responses.482.schema.$ref: '#/definitions/ImageTooLargeException'
paths./#DetectLabels.post.responses.483.description: AccessDeniedException
paths./#DetectLabels.post.responses.483.schema.$ref: '#/definitions/AccessDeniedException'
paths./#DetectLabels.post.responses.484.description: InternalServerError
paths./#DetectLabels.post.responses.484.schema.$ref: '#/definitions/InternalServerError'
paths./#DetectLabels.post.responses.485.description: ThrottlingException
paths./#DetectLabels.post.responses.485.schema.$ref: '#/definitions/ThrottlingException'
paths./#DetectLabels.post.responses.486.description: ProvisionedThroughputExceededException
paths./#DetectLabels.post.responses.486.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./#DetectLabels.post.responses.487.description: InvalidImageFormatException
paths./#DetectLabels.post.responses.487.schema.$ref: '#/definitions/InvalidImageFormatException'
paths./#DetectModerationLabels.parameters.length: 9
paths./#DetectModerationLabels.parameters[0].$ref: '#/parameters/Action'
paths./#DetectModerationLabels.parameters[1].$ref: '#/parameters/Version'
paths./#DetectModerationLabels.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./#DetectModerationLabels.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./#DetectModerationLabels.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./#DetectModerationLabels.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./#DetectModerationLabels.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./#DetectModerationLabels.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./#DetectModerationLabels.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./#DetectModerationLabels.post.description: <p>Detects explicit or suggestive
  adult content in a specified JPEG or PNG format image. Use <code>DetectModerationLabels</code>
  to moderate images depending on your requirements. For example, you might want to
  filter images that contain nudity, but not images containing suggestive content.</p>
  <p>To filter images, use the labels returned by <code>DetectModerationLabels</code>
  to determine which types of content are appropriate. For information about moderation
  labels, see <a>image-moderation</a>.</p>
paths./#DetectModerationLabels.post.operationId: DetectModerationLabels
paths./#DetectModerationLabels.post.parameters.length: 1
paths./#DetectModerationLabels.post.parameters[0].in: body
paths./#DetectModerationLabels.post.parameters[0].name: body
paths./#DetectModerationLabels.post.parameters[0].required: true
paths./#DetectModerationLabels.post.parameters[0].schema.$ref: '#/definitions/DetectModerationLabelsRequest'
paths./#DetectModerationLabels.post.responses.200.description: Success
paths./#DetectModerationLabels.post.responses.200.schema.$ref: '#/definitions/DetectModerationLabelsResponse'
paths./#DetectModerationLabels.post.responses.480.description: InvalidS3ObjectException
paths./#DetectModerationLabels.post.responses.480.schema.$ref: '#/definitions/InvalidS3ObjectException'
paths./#DetectModerationLabels.post.responses.481.description: InvalidParameterException
paths./#DetectModerationLabels.post.responses.481.schema.$ref: '#/definitions/InvalidParameterException'
paths./#DetectModerationLabels.post.responses.482.description: ImageTooLargeException
paths./#DetectModerationLabels.post.responses.482.schema.$ref: '#/definitions/ImageTooLargeException'
paths./#DetectModerationLabels.post.responses.483.description: AccessDeniedException
paths./#DetectModerationLabels.post.responses.483.schema.$ref: '#/definitions/AccessDeniedException'
paths./#DetectModerationLabels.post.responses.484.description: InternalServerError
paths./#DetectModerationLabels.post.responses.484.schema.$ref: '#/definitions/InternalServerError'
paths./#DetectModerationLabels.post.responses.485.description: ThrottlingException
paths./#DetectModerationLabels.post.responses.485.schema.$ref: '#/definitions/ThrottlingException'
paths./#DetectModerationLabels.post.responses.486.description: ProvisionedThroughputExceededException
paths./#DetectModerationLabels.post.responses.486.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./#DetectModerationLabels.post.responses.487.description: InvalidImageFormatException
paths./#DetectModerationLabels.post.responses.487.schema.$ref: '#/definitions/InvalidImageFormatException'
paths./#GetCelebrityInfo.parameters.length: 9
paths./#GetCelebrityInfo.parameters[0].$ref: '#/parameters/Action'
paths./#GetCelebrityInfo.parameters[1].$ref: '#/parameters/Version'
paths./#GetCelebrityInfo.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./#GetCelebrityInfo.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./#GetCelebrityInfo.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./#GetCelebrityInfo.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./#GetCelebrityInfo.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./#GetCelebrityInfo.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./#GetCelebrityInfo.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./#GetCelebrityInfo.post.description: <p>Gets the name and additional information
  about a celebrity based on his or her Rekognition ID. The additional information
  is returned as an array of URLs. If there is no additional information about the
  celebrity, this list is empty. For more information, see <a>celebrity-recognition</a>.</p>
  <p>This operation requires permissions to perform the <code>rekognition:GetCelebrityInfo</code>
  action. </p>
paths./#GetCelebrityInfo.post.operationId: GetCelebrityInfo
paths./#GetCelebrityInfo.post.parameters.length: 1
paths./#GetCelebrityInfo.post.parameters[0].in: body
paths./#GetCelebrityInfo.post.parameters[0].name: body
paths./#GetCelebrityInfo.post.parameters[0].required: true
paths./#GetCelebrityInfo.post.parameters[0].schema.$ref: '#/definitions/GetCelebrityInfoRequest'
paths./#GetCelebrityInfo.post.responses.200.description: Success
paths./#GetCelebrityInfo.post.responses.200.schema.$ref: '#/definitions/GetCelebrityInfoResponse'
paths./#GetCelebrityInfo.post.responses.480.description: InvalidParameterException
paths./#GetCelebrityInfo.post.responses.480.schema.$ref: '#/definitions/InvalidParameterException'
paths./#GetCelebrityInfo.post.responses.481.description: AccessDeniedException
paths./#GetCelebrityInfo.post.responses.481.schema.$ref: '#/definitions/AccessDeniedException'
paths./#GetCelebrityInfo.post.responses.482.description: InternalServerError
paths./#GetCelebrityInfo.post.responses.482.schema.$ref: '#/definitions/InternalServerError'
paths./#GetCelebrityInfo.post.responses.483.description: ThrottlingException
paths./#GetCelebrityInfo.post.responses.483.schema.$ref: '#/definitions/ThrottlingException'
paths./#GetCelebrityInfo.post.responses.484.description: ProvisionedThroughputExceededException
paths./#GetCelebrityInfo.post.responses.484.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./#GetCelebrityInfo.post.responses.485.description: ResourceNotFoundException
paths./#GetCelebrityInfo.post.responses.485.schema.$ref: '#/definitions/ResourceNotFoundException'
paths./#IndexFaces.parameters.length: 9
paths./#IndexFaces.parameters[0].$ref: '#/parameters/Action'
paths./#IndexFaces.parameters[1].$ref: '#/parameters/Version'
paths./#IndexFaces.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./#IndexFaces.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./#IndexFaces.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./#IndexFaces.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./#IndexFaces.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./#IndexFaces.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./#IndexFaces.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./#IndexFaces.post.description: <p>Detects faces in the input image and adds
  them to the specified collection. </p> <p> Amazon Rekognition does not save the
  actual faces detected. Instead, the underlying detection algorithm first detects
  the faces in the input image, and for each face extracts facial features into a
  feature vector, and stores it in the back-end database. Amazon Rekognition uses
  feature vectors when performing face match and search operations using the and operations.
  </p> <p>If you provide the optional <code>externalImageID</code> for the input image
  you provided, Amazon Rekognition associates this ID with all faces that it detects.
  When you call the operation, the response returns the external ID. You can use this
  external image ID to create a client-side index to associate the faces with each
  image. You can then use the index to find all faces in an image. </p> <p>In response,
  the operation returns an array of metadata for all detected faces. This includes,
  the bounding box of the detected face, confidence value (indicating the bounding
  box contains a face), a face ID assigned by the service for each face that is detected
  and stored, and an image ID assigned by the service for the input image. If you
  request all facial attributes (using the <code>detectionAttributes</code> parameter,
  Amazon Rekognition returns detailed facial attributes such as facial landmarks (for
  example, location of eye and mount) and other facial attributes such gender. If
  you provide the same image, specify the same collection, and use the same external
  ID in the <code>IndexFaces</code> operation, Amazon Rekognition doesn't save duplicate
  face metadata. </p> <p>For an example, see <a>example2</a>.</p> <p>This operation
  requires permissions to perform the <code>rekognition:IndexFaces</code> action.</p>
paths./#IndexFaces.post.operationId: IndexFaces
paths./#IndexFaces.post.parameters.length: 1
paths./#IndexFaces.post.parameters[0].in: body
paths./#IndexFaces.post.parameters[0].name: body
paths./#IndexFaces.post.parameters[0].required: true
paths./#IndexFaces.post.parameters[0].schema.$ref: '#/definitions/IndexFacesRequest'
paths./#IndexFaces.post.responses.200.description: Success
paths./#IndexFaces.post.responses.200.schema.$ref: '#/definitions/IndexFacesResponse'
paths./#IndexFaces.post.responses.480.description: InvalidS3ObjectException
paths./#IndexFaces.post.responses.480.schema.$ref: '#/definitions/InvalidS3ObjectException'
paths./#IndexFaces.post.responses.481.description: InvalidParameterException
paths./#IndexFaces.post.responses.481.schema.$ref: '#/definitions/InvalidParameterException'
paths./#IndexFaces.post.responses.482.description: ImageTooLargeException
paths./#IndexFaces.post.responses.482.schema.$ref: '#/definitions/ImageTooLargeException'
paths./#IndexFaces.post.responses.483.description: AccessDeniedException
paths./#IndexFaces.post.responses.483.schema.$ref: '#/definitions/AccessDeniedException'
paths./#IndexFaces.post.responses.484.description: InternalServerError
paths./#IndexFaces.post.responses.484.schema.$ref: '#/definitions/InternalServerError'
paths./#IndexFaces.post.responses.485.description: ThrottlingException
paths./#IndexFaces.post.responses.485.schema.$ref: '#/definitions/ThrottlingException'
paths./#IndexFaces.post.responses.486.description: ProvisionedThroughputExceededException
paths./#IndexFaces.post.responses.486.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./#IndexFaces.post.responses.487.description: ResourceNotFoundException
paths./#IndexFaces.post.responses.487.schema.$ref: '#/definitions/ResourceNotFoundException'
paths./#IndexFaces.post.responses.488.description: InvalidImageFormatException
paths./#IndexFaces.post.responses.488.schema.$ref: '#/definitions/InvalidImageFormatException'
paths./#ListCollections.parameters.length: 9
paths./#ListCollections.parameters[0].$ref: '#/parameters/Action'
paths./#ListCollections.parameters[1].$ref: '#/parameters/Version'
paths./#ListCollections.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./#ListCollections.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./#ListCollections.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./#ListCollections.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./#ListCollections.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./#ListCollections.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./#ListCollections.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./#ListCollections.post.description: <p>Returns list of collection IDs in your
  account. If the result is truncated, the response also provides a <code>NextToken</code>
  that you can use in the subsequent request to fetch the next set of collection IDs.</p>
  <p>For an example, see <a>example1</a>.</p> <p>This operation requires permissions
  to perform the <code>rekognition:ListCollections</code> action.</p>
paths./#ListCollections.post.operationId: ListCollections
paths./#ListCollections.post.parameters.length: 3
paths./#ListCollections.post.parameters[0].in: body
paths./#ListCollections.post.parameters[0].name: body
paths./#ListCollections.post.parameters[0].required: true
paths./#ListCollections.post.parameters[0].schema.$ref: '#/definitions/ListCollectionsRequest'
paths./#ListCollections.post.parameters[1].description: Pagination limit
paths./#ListCollections.post.parameters[1].in: query
paths./#ListCollections.post.parameters[1].name: MaxResults
paths./#ListCollections.post.parameters[1].required: false
paths./#ListCollections.post.parameters[1].type: string
paths./#ListCollections.post.parameters[2].description: Pagination token
paths./#ListCollections.post.parameters[2].in: query
paths./#ListCollections.post.parameters[2].name: NextToken
paths./#ListCollections.post.parameters[2].required: false
paths./#ListCollections.post.parameters[2].type: string
paths./#ListCollections.post.responses.200.description: Success
paths./#ListCollections.post.responses.200.schema.$ref: '#/definitions/ListCollectionsResponse'
paths./#ListCollections.post.responses.480.description: InvalidParameterException
paths./#ListCollections.post.responses.480.schema.$ref: '#/definitions/InvalidParameterException'
paths./#ListCollections.post.responses.481.description: AccessDeniedException
paths./#ListCollections.post.responses.481.schema.$ref: '#/definitions/AccessDeniedException'
paths./#ListCollections.post.responses.482.description: InternalServerError
paths./#ListCollections.post.responses.482.schema.$ref: '#/definitions/InternalServerError'
paths./#ListCollections.post.responses.483.description: ThrottlingException
paths./#ListCollections.post.responses.483.schema.$ref: '#/definitions/ThrottlingException'
paths./#ListCollections.post.responses.484.description: ProvisionedThroughputExceededException
paths./#ListCollections.post.responses.484.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./#ListCollections.post.responses.485.description: InvalidPaginationTokenException
paths./#ListCollections.post.responses.485.schema.$ref: '#/definitions/InvalidPaginationTokenException'
paths./#ListCollections.post.responses.486.description: ResourceNotFoundException
paths./#ListCollections.post.responses.486.schema.$ref: '#/definitions/ResourceNotFoundException'
paths./#ListFaces.parameters.length: 9
paths./#ListFaces.parameters[0].$ref: '#/parameters/Action'
paths./#ListFaces.parameters[1].$ref: '#/parameters/Version'
paths./#ListFaces.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./#ListFaces.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./#ListFaces.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./#ListFaces.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./#ListFaces.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./#ListFaces.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./#ListFaces.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./#ListFaces.post.description: <p>Returns metadata for faces in the specified
  collection. This metadata includes information such as the bounding box coordinates,
  the confidence (that the bounding box contains a face), and face ID. For an example,
  see <a>example3</a>. </p> <p>This operation requires permissions to perform the
  <code>rekognition:ListFaces</code> action.</p>
paths./#ListFaces.post.operationId: ListFaces
paths./#ListFaces.post.parameters.length: 3
paths./#ListFaces.post.parameters[0].in: body
paths./#ListFaces.post.parameters[0].name: body
paths./#ListFaces.post.parameters[0].required: true
paths./#ListFaces.post.parameters[0].schema.$ref: '#/definitions/ListFacesRequest'
paths./#ListFaces.post.parameters[1].description: Pagination limit
paths./#ListFaces.post.parameters[1].in: query
paths./#ListFaces.post.parameters[1].name: MaxResults
paths./#ListFaces.post.parameters[1].required: false
paths./#ListFaces.post.parameters[1].type: string
paths./#ListFaces.post.parameters[2].description: Pagination token
paths./#ListFaces.post.parameters[2].in: query
paths./#ListFaces.post.parameters[2].name: NextToken
paths./#ListFaces.post.parameters[2].required: false
paths./#ListFaces.post.parameters[2].type: string
paths./#ListFaces.post.responses.200.description: Success
paths./#ListFaces.post.responses.200.schema.$ref: '#/definitions/ListFacesResponse'
paths./#ListFaces.post.responses.480.description: InvalidParameterException
paths./#ListFaces.post.responses.480.schema.$ref: '#/definitions/InvalidParameterException'
paths./#ListFaces.post.responses.481.description: AccessDeniedException
paths./#ListFaces.post.responses.481.schema.$ref: '#/definitions/AccessDeniedException'
paths./#ListFaces.post.responses.482.description: InternalServerError
paths./#ListFaces.post.responses.482.schema.$ref: '#/definitions/InternalServerError'
paths./#ListFaces.post.responses.483.description: ThrottlingException
paths./#ListFaces.post.responses.483.schema.$ref: '#/definitions/ThrottlingException'
paths./#ListFaces.post.responses.484.description: ProvisionedThroughputExceededException
paths./#ListFaces.post.responses.484.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./#ListFaces.post.responses.485.description: InvalidPaginationTokenException
paths./#ListFaces.post.responses.485.schema.$ref: '#/definitions/InvalidPaginationTokenException'
paths./#ListFaces.post.responses.486.description: ResourceNotFoundException
paths./#ListFaces.post.responses.486.schema.$ref: '#/definitions/ResourceNotFoundException'
paths./#RecognizeCelebrities.parameters.length: 9
paths./#RecognizeCelebrities.parameters[0].$ref: '#/parameters/Action'
paths./#RecognizeCelebrities.parameters[1].$ref: '#/parameters/Version'
paths./#RecognizeCelebrities.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./#RecognizeCelebrities.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./#RecognizeCelebrities.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./#RecognizeCelebrities.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./#RecognizeCelebrities.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./#RecognizeCelebrities.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./#RecognizeCelebrities.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./#RecognizeCelebrities.post.description: <p>Returns an array of celebrities
  recognized in the input image. The image is passed either as base64-encoded image
  bytes or as a reference to an image in an Amazon S3 bucket. The image must be either
  a PNG or JPEG formatted file. For more information, see <a>celebrity-recognition</a>.
  </p> <p> <code>RecognizeCelebrities</code> returns the 15 largest faces in the image.
  It lists recognized celebrities in the <code>CelebrityFaces</code> list and unrecognized
  faces in the <code>UnrecognizedFaces</code> list. The operation doesn't return celebrities
  whose face sizes are smaller than the largest 15 faces in the image.</p> <p>For
  each celebrity recognized, the API returns a <code>Celebrity</code> object. The
  <code>Celebrity</code> object contains the celebrity name, ID, URL links to additional
  information, match confidence, and a <code>ComparedFace</code> object that you can
  use to locate the celebrity's face on the image.</p> <p>Rekognition does not retain
  information about which images a celebrity has been recognized in. Your application
  must store this information and use the <code>Celebrity</code> ID property as a
  unique identifier for the celebrity. If you don't store the celebrity name or additional
  information URLs returned by <code>RecognizeCelebrities</code>, you will need the
  ID to identify the celebrity in a call to the operation.</p> <p>For an example,
  see <a>recognize-celebrities-tutorial</a>.</p> <p>This operation requires permissions
  to perform the <code>rekognition:RecognizeCelebrities</code> operation.</p>
paths./#RecognizeCelebrities.post.operationId: RecognizeCelebrities
paths./#RecognizeCelebrities.post.parameters.length: 1
paths./#RecognizeCelebrities.post.parameters[0].in: body
paths./#RecognizeCelebrities.post.parameters[0].name: body
paths./#RecognizeCelebrities.post.parameters[0].required: true
paths./#RecognizeCelebrities.post.parameters[0].schema.$ref: '#/definitions/RecognizeCelebritiesRequest'
paths./#RecognizeCelebrities.post.responses.200.description: Success
paths./#RecognizeCelebrities.post.responses.200.schema.$ref: '#/definitions/RecognizeCelebritiesResponse'
paths./#RecognizeCelebrities.post.responses.480.description: InvalidS3ObjectException
paths./#RecognizeCelebrities.post.responses.480.schema.$ref: '#/definitions/InvalidS3ObjectException'
paths./#RecognizeCelebrities.post.responses.481.description: InvalidParameterException
paths./#RecognizeCelebrities.post.responses.481.schema.$ref: '#/definitions/InvalidParameterException'
paths./#RecognizeCelebrities.post.responses.482.description: InvalidImageFormatException
paths./#RecognizeCelebrities.post.responses.482.schema.$ref: '#/definitions/InvalidImageFormatException'
paths./#RecognizeCelebrities.post.responses.483.description: ImageTooLargeException
paths./#RecognizeCelebrities.post.responses.483.schema.$ref: '#/definitions/ImageTooLargeException'
paths./#RecognizeCelebrities.post.responses.484.description: AccessDeniedException
paths./#RecognizeCelebrities.post.responses.484.schema.$ref: '#/definitions/AccessDeniedException'
paths./#RecognizeCelebrities.post.responses.485.description: InternalServerError
paths./#RecognizeCelebrities.post.responses.485.schema.$ref: '#/definitions/InternalServerError'
paths./#RecognizeCelebrities.post.responses.486.description: ThrottlingException
paths./#RecognizeCelebrities.post.responses.486.schema.$ref: '#/definitions/ThrottlingException'
paths./#RecognizeCelebrities.post.responses.487.description: ProvisionedThroughputExceededException
paths./#RecognizeCelebrities.post.responses.487.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./#RecognizeCelebrities.post.responses.488.description: InvalidImageFormatException
paths./#RecognizeCelebrities.post.responses.488.schema.$ref: '#/definitions/InvalidImageFormatException'
paths./#SearchFaces.parameters.length: 9
paths./#SearchFaces.parameters[0].$ref: '#/parameters/Action'
paths./#SearchFaces.parameters[1].$ref: '#/parameters/Version'
paths./#SearchFaces.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./#SearchFaces.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./#SearchFaces.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./#SearchFaces.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./#SearchFaces.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./#SearchFaces.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./#SearchFaces.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./#SearchFaces.post.description: <p>For a given input face ID, searches for matching
  faces in the collection the face belongs to. You get a face ID when you add a face
  to the collection using the <a>IndexFaces</a> operation. The operation compares
  the features of the input face with faces in the specified collection. </p> <note>
  <p>You can also search faces without indexing faces by using the <code>SearchFacesByImage</code>
  operation.</p> </note> <p> The operation response returns an array of faces that
  match, ordered by similarity score with the highest similarity first. More specifically,
  it is an array of metadata for each face match that is found. Along with the metadata,
  the response also includes a <code>confidence</code> value for each face match,
  indicating the confidence that the specific face matches the input face. </p> <p>For
  an example, see <a>example3</a>.</p> <p>This operation requires permissions to perform
  the <code>rekognition:SearchFaces</code> action.</p>
paths./#SearchFaces.post.operationId: SearchFaces
paths./#SearchFaces.post.parameters.length: 1
paths./#SearchFaces.post.parameters[0].in: body
paths./#SearchFaces.post.parameters[0].name: body
paths./#SearchFaces.post.parameters[0].required: true
paths./#SearchFaces.post.parameters[0].schema.$ref: '#/definitions/SearchFacesRequest'
paths./#SearchFaces.post.responses.200.description: Success
paths./#SearchFaces.post.responses.200.schema.$ref: '#/definitions/SearchFacesResponse'
paths./#SearchFaces.post.responses.480.description: InvalidParameterException
paths./#SearchFaces.post.responses.480.schema.$ref: '#/definitions/InvalidParameterException'
paths./#SearchFaces.post.responses.481.description: AccessDeniedException
paths./#SearchFaces.post.responses.481.schema.$ref: '#/definitions/AccessDeniedException'
paths./#SearchFaces.post.responses.482.description: InternalServerError
paths./#SearchFaces.post.responses.482.schema.$ref: '#/definitions/InternalServerError'
paths./#SearchFaces.post.responses.483.description: ThrottlingException
paths./#SearchFaces.post.responses.483.schema.$ref: '#/definitions/ThrottlingException'
paths./#SearchFaces.post.responses.484.description: ProvisionedThroughputExceededException
paths./#SearchFaces.post.responses.484.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./#SearchFaces.post.responses.485.description: ResourceNotFoundException
paths./#SearchFaces.post.responses.485.schema.$ref: '#/definitions/ResourceNotFoundException'
paths./#SearchFacesByImage.parameters.length: 9
paths./#SearchFacesByImage.parameters[0].$ref: '#/parameters/Action'
paths./#SearchFacesByImage.parameters[1].$ref: '#/parameters/Version'
paths./#SearchFacesByImage.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./#SearchFacesByImage.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./#SearchFacesByImage.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./#SearchFacesByImage.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./#SearchFacesByImage.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./#SearchFacesByImage.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./#SearchFacesByImage.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./#SearchFacesByImage.post.description: <p>For a given input image, first detects
  the largest face in the image, and then searches the specified collection for matching
  faces. The operation compares the features of the input face with faces in the specified
  collection. </p> <note> <p> To search for all faces in an input image, you might
  first call the operation, and then use the face IDs returned in subsequent calls
  to the operation. </p> <p> You can also call the <code>DetectFaces</code> operation
  and use the bounding boxes in the response to make face crops, which then you can
  pass in to the <code>SearchFacesByImage</code> operation. </p> </note> <p> The response
  returns an array of faces that match, ordered by similarity score with the highest
  similarity first. More specifically, it is an array of metadata for each face match
  found. Along with the metadata, the response also includes a <code>similarity</code>
  indicating how similar the face is to the input face. In the response, the operation
  also returns the bounding box (and a confidence level that the bounding box contains
  a face) of the face that Amazon Rekognition used for the input image. </p> <p>For
  an example, see <a>example3</a>.</p> <p>This operation requires permissions to perform
  the <code>rekognition:SearchFacesByImage</code> action.</p>
paths./#SearchFacesByImage.post.operationId: SearchFacesByImage
paths./#SearchFacesByImage.post.parameters.length: 1
paths./#SearchFacesByImage.post.parameters[0].in: body
paths./#SearchFacesByImage.post.parameters[0].name: body
paths./#SearchFacesByImage.post.parameters[0].required: true
paths./#SearchFacesByImage.post.parameters[0].schema.$ref: '#/definitions/SearchFacesByImageRequest'
paths./#SearchFacesByImage.post.responses.200.description: Success
paths./#SearchFacesByImage.post.responses.200.schema.$ref: '#/definitions/SearchFacesByImageResponse'
paths./#SearchFacesByImage.post.responses.480.description: InvalidS3ObjectException
paths./#SearchFacesByImage.post.responses.480.schema.$ref: '#/definitions/InvalidS3ObjectException'
paths./#SearchFacesByImage.post.responses.481.description: InvalidParameterException
paths./#SearchFacesByImage.post.responses.481.schema.$ref: '#/definitions/InvalidParameterException'
paths./#SearchFacesByImage.post.responses.482.description: ImageTooLargeException
paths./#SearchFacesByImage.post.responses.482.schema.$ref: '#/definitions/ImageTooLargeException'
paths./#SearchFacesByImage.post.responses.483.description: AccessDeniedException
paths./#SearchFacesByImage.post.responses.483.schema.$ref: '#/definitions/AccessDeniedException'
paths./#SearchFacesByImage.post.responses.484.description: InternalServerError
paths./#SearchFacesByImage.post.responses.484.schema.$ref: '#/definitions/InternalServerError'
paths./#SearchFacesByImage.post.responses.485.description: ThrottlingException
paths./#SearchFacesByImage.post.responses.485.schema.$ref: '#/definitions/ThrottlingException'
paths./#SearchFacesByImage.post.responses.486.description: ProvisionedThroughputExceededException
paths./#SearchFacesByImage.post.responses.486.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./#SearchFacesByImage.post.responses.487.description: ResourceNotFoundException
paths./#SearchFacesByImage.post.responses.487.schema.$ref: '#/definitions/ResourceNotFoundException'
paths./#SearchFacesByImage.post.responses.488.description: InvalidImageFormatException
paths./#SearchFacesByImage.post.responses.488.schema.$ref: '#/definitions/InvalidImageFormatException'
paths./.parameters.length: 9
paths./.parameters[0].$ref: '#/parameters/Action'
paths./.parameters[1].$ref: '#/parameters/Version'
paths./.parameters[2].$ref: '#/parameters/X-Amz-Content-Sha256'
paths./.parameters[3].$ref: '#/parameters/X-Amz-Date'
paths./.parameters[4].$ref: '#/parameters/X-Amz-Algorithm'
paths./.parameters[5].$ref: '#/parameters/X-Amz-Credential'
paths./.parameters[6].$ref: '#/parameters/X-Amz-Security-Token'
paths./.parameters[7].$ref: '#/parameters/X-Amz-Signature'
paths./.parameters[8].$ref: '#/parameters/X-Amz-SignedHeaders'
paths./.post.description: <p>Compares a face in the <i>source</i> input image with
  each face detected in the <i>target</i> input image. </p> <note> <p> If the source
  image contains multiple faces, the service detects the largest face and compares
  it with each face detected in the target image. </p> </note> <p>In response, the
  operation returns an array of face matches ordered by similarity score in descending
  order. For each face match, the response provides a bounding box of the face, facial
  landmarks, pose details (pitch, role, and yaw), quality (brightness and sharpness),
  and confidence value (indicating the level of confidence that the bounding box contains
  a face). The response also provides a similarity score, which indicates how closely
  the faces match. </p> <note> <p>By default, only faces with a similarity score of
  greater than or equal to 80% are returned in the response. You can change this value
  by specifying the <code>SimilarityThreshold</code> parameter.</p> </note> <p> <code>CompareFaces</code>
  also returns an array of faces that don't match the source image. For each face,
  it returns a bounding box, confidence value, landmarks, pose details, and quality.
  The response also returns information about the face in the source image, including
  the bounding box of the face and confidence value.</p> <p>If the image doesn't contain
  Exif metadata, <code>CompareFaces</code> returns orientation information for the
  source and target images. Use these values to display the images with the correct
  image orientation.</p> <note> <p> This is a stateless API operation. That is, data
  returned by this operation doesn't persist.</p> </note> <p>For an example, see <a>get-started-exercise-compare-faces</a>.</p>
  <p>This operation requires permissions to perform the <code>rekognition:CompareFaces</code>
  action.</p>
paths./.post.operationId: CompareFaces
paths./.post.parameters.length: 1
paths./.post.parameters[0].in: body
paths./.post.parameters[0].name: body
paths./.post.parameters[0].required: true
paths./.post.parameters[0].schema.$ref: '#/definitions/CompareFacesRequest'
paths./.post.responses.200.description: Success
paths./.post.responses.200.schema.$ref: '#/definitions/CompareFacesResponse'
paths./.post.responses.480.description: InvalidParameterException
paths./.post.responses.480.schema.$ref: '#/definitions/InvalidParameterException'
paths./.post.responses.481.description: InvalidS3ObjectException
paths./.post.responses.481.schema.$ref: '#/definitions/InvalidS3ObjectException'
paths./.post.responses.482.description: ImageTooLargeException
paths./.post.responses.482.schema.$ref: '#/definitions/ImageTooLargeException'
paths./.post.responses.483.description: AccessDeniedException
paths./.post.responses.483.schema.$ref: '#/definitions/AccessDeniedException'
paths./.post.responses.484.description: InternalServerError
paths./.post.responses.484.schema.$ref: '#/definitions/InternalServerError'
paths./.post.responses.485.description: ThrottlingException
paths./.post.responses.485.schema.$ref: '#/definitions/ThrottlingException'
paths./.post.responses.486.description: ProvisionedThroughputExceededException
paths./.post.responses.486.schema.$ref: '#/definitions/ProvisionedThroughputExceededException'
paths./.post.responses.487.description: InvalidImageFormatException
paths./.post.responses.487.schema.$ref: '#/definitions/InvalidImageFormatException'
produces.length: 1
produces[0]: application/json
schemes.length: 1
schemes[0]: http
security.length: 1
security[0].hmac.length: 0
securityDefinitions.hmac.description: Amazon Signature authorization v4
securityDefinitions.hmac.in: header
securityDefinitions.hmac.name: Authorization
securityDefinitions.hmac.type: apiKey
securityDefinitions.hmac.x-amazon-apigateway-authtype: awsSigv4
swagger: "2.0"
x-hasEquivalentPaths: true
